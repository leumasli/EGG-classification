{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDxR_u4x9LU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07woaV2yKsc",
        "outputId": "c7184219-bc30-4418-8f1b-47f25782aa98"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 12.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 9.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9BCN7EPyT4c",
        "outputId": "86206357-c953-4b3b-a085-d09a96968ecd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/EE147"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/EE147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8_04zlex9LV"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDQJhSO1x9LV"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Amrz-W8FYCA",
        "outputId": "8a1c2a62-2fbc-471f-82a6-7a5535685a2d"
      },
      "source": [
        "import utils.dataprep as dp\r\n",
        "# Package returned variables in 'raw' variable (create new variables for each value)\r\n",
        "raw = lambda _: ()\r\n",
        "(raw.X_train_valid, raw.y_train_valid, _), (raw.X_test, raw.y_test, _) = dp.load_data()\r\n",
        "\r\n",
        "print('\\n---- Splitting Data ----')\r\n",
        "(raw.X_train, raw.y_train), (raw.X_valid, raw.y_valid) = \\\r\n",
        "    dp.split_data(raw.X_train_valid, raw.y_train_valid)\r\n",
        "\r\n",
        "print('\\n---- Augmenting Data ----')\r\n",
        "prep = lambda _: ()\r\n",
        "prep.X_train, prep.y_train = dp.data_prep(raw.X_train, raw.y_train, 2, 2)\r\n",
        "print('X-train', prep.X_train.shape, 'with labels', prep.y_train.shape)\r\n",
        "prep.X_valid, prep.y_valid = dp.data_prep(raw.X_valid, raw.y_valid, 2, 2)\r\n",
        "print('X-valid', prep.X_valid.shape, 'with labels', prep.y_valid.shape)\r\n",
        "prep.X_test,  prep.y_test  = dp.data_prep(raw.X_test,  raw.y_test,  2, 2)\r\n",
        "print('X-test', prep.X_test.shape, 'with labels', prep.y_test.shape)\r\n",
        "\r\n",
        "X_train = prep.X_train.reshape(*prep.X_train.shape, 1)\r\n",
        "X_train = np.swapaxes(X_train, 1, 2)\r\n",
        "y_train = prep.y_train\r\n",
        "\r\n",
        "X_valid = prep.X_valid.reshape(*prep.X_valid.shape, 1)\r\n",
        "X_valid = np.swapaxes(X_valid, 1, 2)\r\n",
        "y_valid = prep.y_valid\r\n",
        "\r\n",
        "X_test = prep.X_test.reshape(*prep.X_test.shape, 1)\r\n",
        "X_test = np.swapaxes(X_test, 1, 2)\r\n",
        "y_test = prep.y_test\r\n",
        "\r\n",
        "print('\\n---- Reshaping Data ----')\r\n",
        "print (\"X-train\", X_train.shape, \"with labels\", y_train.shape)\r\n",
        "print (\"X-valid\", X_valid.shape, \"with labels\", y_valid.shape)\r\n",
        "print (\"X-test\", X_test.shape, \"with labels\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from /content/drive/Shareddrives/EE147/project_data/\n",
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Person train/valid shape: (2115,)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Test target shape: (443,)\n",
            "Person test shape: (443,)\n",
            "\n",
            "---- Splitting Data ----\n",
            "Training Data: (1692, 22, 1000) with labels (1692,)\n",
            "Validate Data: (423, 22, 1000) with labels (423,)\n",
            "\n",
            "---- Augmenting Data ----\n",
            "X-train (6768, 22, 250) with labels (6768,)\n",
            "X-valid (1692, 22, 250) with labels (1692,)\n",
            "X-test (1772, 22, 250) with labels (1772,)\n",
            "\n",
            "---- Reshaping Data ----\n",
            "X-train (6768, 250, 22, 1) with labels (6768,)\n",
            "X-valid (1692, 250, 22, 1) with labels (1692,)\n",
            "X-test (1772, 250, 22, 1) with labels (1772,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCeUNnwUx9LV"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUKH-LS-x9LV"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-4\n",
        "batch_size = 256\n",
        "num_epochs = 500\n",
        "image_size = 250  # We'll resize input images to this size\n",
        "patch_size = 10  # Size of the patches to be extract from the input images\n",
        "patch_width = 22\n",
        "num_patches = image_size * 22 // (patch_size * patch_width)\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [128, 64]  # Size of the dense layers of the final classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uo_v6grx9LW"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY0o490Ix9LW"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9s5El0kx9LW"
      },
      "source": [
        "## Patch creation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OIzz3fx9LX"
      },
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, patch_width, 1],\n",
        "            strides=[1, self.patch_size, patch_width, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk2czLA4x9LX"
      },
      "source": [
        "Display patches for a sample image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TNwHgxCx9LX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "6bee7932-900c-4b3d-e523-2d6672ba4bc9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = X_train[np.random.choice(range(X_train.shape[0]))]\n",
        "plt.imshow(image.reshape((250, 22)).astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, patch_width)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "# print(f\"Image size: {image_size} X {image_size}\")\n",
        "# print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "# print(f\"Patches per image: {patches.shape[1]}\")\n",
        "# print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "print(resized_image.shape)\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_width, 1))\n",
        "    plt.imshow(patch_img.numpy().reshape((patch_size, patch_width)).astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 250, 22, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SMTSWk5x9LX"
      },
      "source": [
        "## Patch encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPouXWs7x9LX"
      },
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQOwuS3sx9LY"
      },
      "source": [
        "## Build the ViT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOYl83ETx9LY"
      },
      "source": [
        "def create_vit_classifier():\n",
        "    input_shape = (250, 22, 1)\n",
        "    num_classes = 4\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    # augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.5\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.5)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes, activation='softmax')(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBJ7GLchx9LZ"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibSrvhg_x9La",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd1c2e5-5e37-453f-e7f0-edace636409c"
      },
      "source": [
        "def run_experiment(model):\n",
        "    # optimizer = tfa.optimizers.AdamW(\n",
        "    #     learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    # )\n",
        "\n",
        "    optimizer = tfa.optimizers.SGDW(\n",
        "        learning_rate=learning_rate, momentum=0.97, weight_decay=weight_decay\n",
        "        )\n",
        "    \n",
        "    # def scheduler(epoch, lr):\n",
        "    #     if epoch % 10 != 0:\n",
        "    #         return lr\n",
        "    #     else:\n",
        "    #         return lr * .5\n",
        "    # lr_decay = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "    lr_decay = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=15, verbose=1)\n",
        "\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=50)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        # loss = keras.losses.CategoricalCrossentropy()\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            # keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/content/drive/Shareddrives/EE147/vit_checkpoint/vit_checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[checkpoint_callback, lr_decay, early_stopping],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    # _, accuracy, top_2_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    # print(f\"Test top 2 accuracy: {round(top_2_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "# history = run_experiment(create_vit_classifier())\n",
        "model = create_vit_classifier()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 250, 22, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "patches_3 (Patches)             (None, None, 220)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "patch_encoder_2 (PatchEncoder)  (None, 25, 64)       15744       patches_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_34 (LayerNo (None, 25, 64)       128         patch_encoder_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_16 (MultiH (None, 25, 64)       66368       layer_normalization_34[0][0]     \n",
            "                                                                 layer_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 25, 64)       0           multi_head_attention_16[0][0]    \n",
            "                                                                 patch_encoder_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_35 (LayerNo (None, 25, 64)       128         add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 25, 128)      8320        layer_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 25, 128)      0           dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 25, 64)       8256        dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 25, 64)       0           dense_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 25, 64)       0           dropout_39[0][0]                 \n",
            "                                                                 add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_36 (LayerNo (None, 25, 64)       128         add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_17 (MultiH (None, 25, 64)       66368       layer_normalization_36[0][0]     \n",
            "                                                                 layer_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 25, 64)       0           multi_head_attention_17[0][0]    \n",
            "                                                                 add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_37 (LayerNo (None, 25, 64)       128         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 25, 128)      8320        layer_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 25, 128)      0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 25, 64)       8256        dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 25, 64)       0           dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 25, 64)       0           dropout_41[0][0]                 \n",
            "                                                                 add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_38 (LayerNo (None, 25, 64)       128         add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_18 (MultiH (None, 25, 64)       66368       layer_normalization_38[0][0]     \n",
            "                                                                 layer_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 25, 64)       0           multi_head_attention_18[0][0]    \n",
            "                                                                 add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_39 (LayerNo (None, 25, 64)       128         add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 25, 128)      8320        layer_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 25, 128)      0           dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 25, 64)       8256        dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 25, 64)       0           dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 25, 64)       0           dropout_43[0][0]                 \n",
            "                                                                 add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_40 (LayerNo (None, 25, 64)       128         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_19 (MultiH (None, 25, 64)       66368       layer_normalization_40[0][0]     \n",
            "                                                                 layer_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 25, 64)       0           multi_head_attention_19[0][0]    \n",
            "                                                                 add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_41 (LayerNo (None, 25, 64)       128         add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 25, 128)      8320        layer_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 25, 128)      0           dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 25, 64)       8256        dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 25, 64)       0           dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 25, 64)       0           dropout_45[0][0]                 \n",
            "                                                                 add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_42 (LayerNo (None, 25, 64)       128         add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_20 (MultiH (None, 25, 64)       66368       layer_normalization_42[0][0]     \n",
            "                                                                 layer_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 25, 64)       0           multi_head_attention_20[0][0]    \n",
            "                                                                 add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_43 (LayerNo (None, 25, 64)       128         add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 25, 128)      8320        layer_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 25, 128)      0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 25, 64)       8256        dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 25, 64)       0           dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 25, 64)       0           dropout_47[0][0]                 \n",
            "                                                                 add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_44 (LayerNo (None, 25, 64)       128         add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_21 (MultiH (None, 25, 64)       66368       layer_normalization_44[0][0]     \n",
            "                                                                 layer_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 25, 64)       0           multi_head_attention_21[0][0]    \n",
            "                                                                 add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_45 (LayerNo (None, 25, 64)       128         add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 25, 128)      8320        layer_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 25, 128)      0           dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 25, 64)       8256        dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 25, 64)       0           dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 25, 64)       0           dropout_49[0][0]                 \n",
            "                                                                 add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_46 (LayerNo (None, 25, 64)       128         add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_22 (MultiH (None, 25, 64)       66368       layer_normalization_46[0][0]     \n",
            "                                                                 layer_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 25, 64)       0           multi_head_attention_22[0][0]    \n",
            "                                                                 add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_47 (LayerNo (None, 25, 64)       128         add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 25, 128)      8320        layer_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 25, 128)      0           dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 25, 64)       8256        dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 25, 64)       0           dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 25, 64)       0           dropout_51[0][0]                 \n",
            "                                                                 add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_48 (LayerNo (None, 25, 64)       128         add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_23 (MultiH (None, 25, 64)       66368       layer_normalization_48[0][0]     \n",
            "                                                                 layer_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 25, 64)       0           multi_head_attention_23[0][0]    \n",
            "                                                                 add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_49 (LayerNo (None, 25, 64)       128         add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 25, 128)      8320        layer_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 25, 128)      0           dense_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 25, 64)       8256        dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 25, 64)       0           dense_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 25, 64)       0           dropout_53[0][0]                 \n",
            "                                                                 add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_50 (LayerNo (None, 25, 64)       128         add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1600)         0           layer_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 1600)         0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 128)          204928      dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 128)          0           dense_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 64)           8256        dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 64)           0           dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 4)            260         dropout_56[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 894,916\n",
            "Trainable params: 894,916\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRihN94JcALG"
      },
      "source": [
        "optimizer = tfa.optimizers.SGDW(\r\n",
        "    learning_rate=learning_rate, momentum=0.95, weight_decay=weight_decay\r\n",
        "    )\r\n",
        "\r\n",
        "# def scheduler(epoch, lr):\r\n",
        "#     if epoch % 10 != 0:\r\n",
        "#         return lr\r\n",
        "#     else:\r\n",
        "#         return lr * .5\r\n",
        "# lr_decay = keras.callbacks.LearningRateScheduler(scheduler)\r\n",
        "lr_decay = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=15, verbose=1)\r\n",
        "\r\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=50)\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=optimizer,\r\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "    # loss = keras.losses.CategoricalCrossentropy()\r\n",
        "    metrics=[\r\n",
        "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\r\n",
        "        # keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\r\n",
        "    ],\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5TBYVJMF38v",
        "outputId": "2e41c1a9-9727-441a-923e-4599c45b8e5f"
      },
      "source": [
        "def run_experiment(model):\n",
        "    # optimizer = tfa.optimizers.AdamW(\n",
        "    #     learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    # )\n",
        "\n",
        "    optimizer = tfa.optimizers.SGDW(\n",
        "        learning_rate=learning_rate, momentum=0.95, weight_decay=weight_decay\n",
        "    )\n",
        "    \n",
        "    lr_decay = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=15, verbose=1)\n",
        "\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=50)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        # loss = keras.losses.CategoricalCrossentropy()\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            # keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/content/drive/Shareddrives/EE147/vit_checkpoint/vit\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[checkpoint_callback, lr_decay, early_stopping],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    # _, accuracy, top_2_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    # print(f\"Test top 2 accuracy: {round(top_2_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "history = run_experiment(create_vit_classifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - 11s 81ms/step - loss: 2.7716 - accuracy: 0.2509 - val_loss: 1.4463 - val_accuracy: 0.2612\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.9659 - accuracy: 0.2711 - val_loss: 1.3806 - val_accuracy: 0.3121\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.6214 - accuracy: 0.2842 - val_loss: 1.3681 - val_accuracy: 0.3103\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.5002 - accuracy: 0.2916 - val_loss: 1.3637 - val_accuracy: 0.3180\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4643 - accuracy: 0.2921 - val_loss: 1.3621 - val_accuracy: 0.3221\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 1.4397 - accuracy: 0.2833 - val_loss: 1.3617 - val_accuracy: 0.3262\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4067 - accuracy: 0.3007 - val_loss: 1.3598 - val_accuracy: 0.3310\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3865 - accuracy: 0.3129 - val_loss: 1.3582 - val_accuracy: 0.3280\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3810 - accuracy: 0.3149 - val_loss: 1.3565 - val_accuracy: 0.3363\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3731 - accuracy: 0.3113 - val_loss: 1.3550 - val_accuracy: 0.3327\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3746 - accuracy: 0.3113 - val_loss: 1.3526 - val_accuracy: 0.3375\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3679 - accuracy: 0.3168 - val_loss: 1.3500 - val_accuracy: 0.3398\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3586 - accuracy: 0.3315 - val_loss: 1.3480 - val_accuracy: 0.3381\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.3484 - accuracy: 0.3406 - val_loss: 1.3448 - val_accuracy: 0.3434\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3497 - accuracy: 0.3373 - val_loss: 1.3426 - val_accuracy: 0.3422\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3463 - accuracy: 0.3500 - val_loss: 1.3391 - val_accuracy: 0.3457\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3476 - accuracy: 0.3383 - val_loss: 1.3363 - val_accuracy: 0.3452\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3307 - accuracy: 0.3532 - val_loss: 1.3326 - val_accuracy: 0.3481\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3228 - accuracy: 0.3697 - val_loss: 1.3292 - val_accuracy: 0.3493\n",
            "Epoch 20/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3327 - accuracy: 0.3598 - val_loss: 1.3258 - val_accuracy: 0.3487\n",
            "Epoch 21/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3234 - accuracy: 0.3568 - val_loss: 1.3225 - val_accuracy: 0.3505\n",
            "Epoch 22/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3131 - accuracy: 0.3734 - val_loss: 1.3202 - val_accuracy: 0.3475\n",
            "Epoch 23/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3158 - accuracy: 0.3777 - val_loss: 1.3177 - val_accuracy: 0.3528\n",
            "Epoch 24/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3097 - accuracy: 0.3847 - val_loss: 1.3153 - val_accuracy: 0.3587\n",
            "Epoch 25/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3051 - accuracy: 0.3899 - val_loss: 1.3119 - val_accuracy: 0.3599\n",
            "Epoch 26/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3096 - accuracy: 0.3730 - val_loss: 1.3085 - val_accuracy: 0.3641\n",
            "Epoch 27/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2954 - accuracy: 0.3896 - val_loss: 1.3047 - val_accuracy: 0.3658\n",
            "Epoch 28/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2922 - accuracy: 0.3816 - val_loss: 1.3016 - val_accuracy: 0.3641\n",
            "Epoch 29/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2777 - accuracy: 0.4024 - val_loss: 1.2995 - val_accuracy: 0.3629\n",
            "Epoch 30/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2901 - accuracy: 0.4019 - val_loss: 1.2969 - val_accuracy: 0.3670\n",
            "Epoch 31/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2867 - accuracy: 0.4018 - val_loss: 1.2956 - val_accuracy: 0.3712\n",
            "Epoch 32/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2659 - accuracy: 0.4137 - val_loss: 1.2926 - val_accuracy: 0.3717\n",
            "Epoch 33/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2646 - accuracy: 0.4107 - val_loss: 1.2889 - val_accuracy: 0.3723\n",
            "Epoch 34/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2675 - accuracy: 0.4075 - val_loss: 1.2855 - val_accuracy: 0.3771\n",
            "Epoch 35/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2574 - accuracy: 0.4078 - val_loss: 1.2831 - val_accuracy: 0.3753\n",
            "Epoch 36/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2462 - accuracy: 0.4306 - val_loss: 1.2818 - val_accuracy: 0.3800\n",
            "Epoch 37/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2403 - accuracy: 0.4249 - val_loss: 1.2796 - val_accuracy: 0.3777\n",
            "Epoch 38/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2247 - accuracy: 0.4386 - val_loss: 1.2766 - val_accuracy: 0.3800\n",
            "Epoch 39/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2314 - accuracy: 0.4450 - val_loss: 1.2731 - val_accuracy: 0.3877\n",
            "Epoch 40/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2248 - accuracy: 0.4423 - val_loss: 1.2711 - val_accuracy: 0.3871\n",
            "Epoch 41/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2246 - accuracy: 0.4457 - val_loss: 1.2674 - val_accuracy: 0.3871\n",
            "Epoch 42/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2264 - accuracy: 0.4450 - val_loss: 1.2630 - val_accuracy: 0.3942\n",
            "Epoch 43/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2152 - accuracy: 0.4524 - val_loss: 1.2599 - val_accuracy: 0.3954\n",
            "Epoch 44/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1926 - accuracy: 0.4541 - val_loss: 1.2567 - val_accuracy: 0.3942\n",
            "Epoch 45/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1943 - accuracy: 0.4595 - val_loss: 1.2539 - val_accuracy: 0.3948\n",
            "Epoch 46/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1918 - accuracy: 0.4640 - val_loss: 1.2506 - val_accuracy: 0.3989\n",
            "Epoch 47/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1841 - accuracy: 0.4722 - val_loss: 1.2448 - val_accuracy: 0.4060\n",
            "Epoch 48/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1743 - accuracy: 0.4767 - val_loss: 1.2404 - val_accuracy: 0.4054\n",
            "Epoch 49/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1670 - accuracy: 0.4753 - val_loss: 1.2365 - val_accuracy: 0.4078\n",
            "Epoch 50/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1673 - accuracy: 0.4663 - val_loss: 1.2320 - val_accuracy: 0.4137\n",
            "Epoch 51/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1503 - accuracy: 0.4876 - val_loss: 1.2278 - val_accuracy: 0.4208\n",
            "Epoch 52/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1460 - accuracy: 0.4883 - val_loss: 1.2237 - val_accuracy: 0.4267\n",
            "Epoch 53/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.1280 - accuracy: 0.4921 - val_loss: 1.2205 - val_accuracy: 0.4255\n",
            "Epoch 54/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1300 - accuracy: 0.4995 - val_loss: 1.2188 - val_accuracy: 0.4243\n",
            "Epoch 55/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1330 - accuracy: 0.4962 - val_loss: 1.2121 - val_accuracy: 0.4309\n",
            "Epoch 56/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1069 - accuracy: 0.5117 - val_loss: 1.2079 - val_accuracy: 0.4332\n",
            "Epoch 57/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1110 - accuracy: 0.5109 - val_loss: 1.2042 - val_accuracy: 0.4379\n",
            "Epoch 58/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1092 - accuracy: 0.5098 - val_loss: 1.1990 - val_accuracy: 0.4427\n",
            "Epoch 59/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1069 - accuracy: 0.5191 - val_loss: 1.1924 - val_accuracy: 0.4474\n",
            "Epoch 60/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0953 - accuracy: 0.5283 - val_loss: 1.1894 - val_accuracy: 0.4468\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0767 - accuracy: 0.5319 - val_loss: 1.1850 - val_accuracy: 0.4515\n",
            "Epoch 62/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0590 - accuracy: 0.5454 - val_loss: 1.1817 - val_accuracy: 0.4509\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0729 - accuracy: 0.5326 - val_loss: 1.1791 - val_accuracy: 0.4557\n",
            "Epoch 64/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0442 - accuracy: 0.5508 - val_loss: 1.1740 - val_accuracy: 0.4639\n",
            "Epoch 65/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 1.0465 - accuracy: 0.5550 - val_loss: 1.1698 - val_accuracy: 0.4716\n",
            "Epoch 66/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0449 - accuracy: 0.5539 - val_loss: 1.1649 - val_accuracy: 0.4775\n",
            "Epoch 67/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0415 - accuracy: 0.5578 - val_loss: 1.1640 - val_accuracy: 0.4770\n",
            "Epoch 68/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0220 - accuracy: 0.5485 - val_loss: 1.1583 - val_accuracy: 0.4728\n",
            "Epoch 69/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0142 - accuracy: 0.5634 - val_loss: 1.1575 - val_accuracy: 0.4740\n",
            "Epoch 70/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0020 - accuracy: 0.5800 - val_loss: 1.1552 - val_accuracy: 0.4805\n",
            "Epoch 71/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.9942 - accuracy: 0.5810 - val_loss: 1.1517 - val_accuracy: 0.4882\n",
            "Epoch 72/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9986 - accuracy: 0.5817 - val_loss: 1.1473 - val_accuracy: 0.4870\n",
            "Epoch 73/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9776 - accuracy: 0.5878 - val_loss: 1.1442 - val_accuracy: 0.4894\n",
            "Epoch 74/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9818 - accuracy: 0.5892 - val_loss: 1.1387 - val_accuracy: 0.5012\n",
            "Epoch 75/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9708 - accuracy: 0.5964 - val_loss: 1.1388 - val_accuracy: 0.5000\n",
            "Epoch 76/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.9799 - accuracy: 0.5831 - val_loss: 1.1374 - val_accuracy: 0.5030\n",
            "Epoch 77/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9428 - accuracy: 0.5940 - val_loss: 1.1389 - val_accuracy: 0.4976\n",
            "Epoch 78/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9431 - accuracy: 0.6166 - val_loss: 1.1342 - val_accuracy: 0.5030\n",
            "Epoch 79/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9342 - accuracy: 0.6060 - val_loss: 1.1315 - val_accuracy: 0.5006\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9265 - accuracy: 0.6162 - val_loss: 1.1307 - val_accuracy: 0.5059\n",
            "Epoch 81/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9076 - accuracy: 0.6312 - val_loss: 1.1262 - val_accuracy: 0.5136\n",
            "Epoch 82/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8973 - accuracy: 0.6383 - val_loss: 1.1221 - val_accuracy: 0.5183\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8871 - accuracy: 0.6463 - val_loss: 1.1221 - val_accuracy: 0.5154\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8825 - accuracy: 0.6382 - val_loss: 1.1153 - val_accuracy: 0.5236\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8891 - accuracy: 0.6403 - val_loss: 1.1145 - val_accuracy: 0.5278\n",
            "Epoch 86/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8762 - accuracy: 0.6422 - val_loss: 1.1135 - val_accuracy: 0.5248\n",
            "Epoch 87/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.8636 - accuracy: 0.6531 - val_loss: 1.1172 - val_accuracy: 0.5213\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8691 - accuracy: 0.6491 - val_loss: 1.1116 - val_accuracy: 0.5189\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8614 - accuracy: 0.6547 - val_loss: 1.1091 - val_accuracy: 0.5248\n",
            "Epoch 90/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8309 - accuracy: 0.6558 - val_loss: 1.1012 - val_accuracy: 0.5272\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8165 - accuracy: 0.6684 - val_loss: 1.1072 - val_accuracy: 0.5272\n",
            "Epoch 92/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.8159 - accuracy: 0.6564 - val_loss: 1.1003 - val_accuracy: 0.5301\n",
            "Epoch 93/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8296 - accuracy: 0.6673 - val_loss: 1.1000 - val_accuracy: 0.5313\n",
            "Epoch 94/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7887 - accuracy: 0.6813 - val_loss: 1.0959 - val_accuracy: 0.5313\n",
            "Epoch 95/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7936 - accuracy: 0.6934 - val_loss: 1.0973 - val_accuracy: 0.5307\n",
            "Epoch 96/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7832 - accuracy: 0.6888 - val_loss: 1.0972 - val_accuracy: 0.5301\n",
            "Epoch 97/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7695 - accuracy: 0.7038 - val_loss: 1.0988 - val_accuracy: 0.5337\n",
            "Epoch 98/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7663 - accuracy: 0.7014 - val_loss: 1.0936 - val_accuracy: 0.5307\n",
            "Epoch 99/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7381 - accuracy: 0.7100 - val_loss: 1.0959 - val_accuracy: 0.5402\n",
            "Epoch 100/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7538 - accuracy: 0.7046 - val_loss: 1.0945 - val_accuracy: 0.5402\n",
            "Epoch 101/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7381 - accuracy: 0.7139 - val_loss: 1.0856 - val_accuracy: 0.5361\n",
            "Epoch 102/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7289 - accuracy: 0.7177 - val_loss: 1.0897 - val_accuracy: 0.5384\n",
            "Epoch 103/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7280 - accuracy: 0.7134 - val_loss: 1.0921 - val_accuracy: 0.5384\n",
            "Epoch 104/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7077 - accuracy: 0.7294 - val_loss: 1.0844 - val_accuracy: 0.5378\n",
            "Epoch 105/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6953 - accuracy: 0.7272 - val_loss: 1.0890 - val_accuracy: 0.5455\n",
            "Epoch 106/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.6775 - accuracy: 0.7373 - val_loss: 1.0902 - val_accuracy: 0.5414\n",
            "Epoch 107/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.6716 - accuracy: 0.7367 - val_loss: 1.0881 - val_accuracy: 0.5384\n",
            "Epoch 108/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6570 - accuracy: 0.7445 - val_loss: 1.0828 - val_accuracy: 0.5437\n",
            "Epoch 109/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6706 - accuracy: 0.7364 - val_loss: 1.0877 - val_accuracy: 0.5414\n",
            "Epoch 110/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6603 - accuracy: 0.7427 - val_loss: 1.0730 - val_accuracy: 0.5544\n",
            "Epoch 111/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6495 - accuracy: 0.7554 - val_loss: 1.0763 - val_accuracy: 0.5567\n",
            "Epoch 112/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6433 - accuracy: 0.7564 - val_loss: 1.0835 - val_accuracy: 0.5556\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6506 - accuracy: 0.7456 - val_loss: 1.0754 - val_accuracy: 0.5526\n",
            "Epoch 114/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6339 - accuracy: 0.7553 - val_loss: 1.0705 - val_accuracy: 0.5508\n",
            "Epoch 115/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6272 - accuracy: 0.7633 - val_loss: 1.0735 - val_accuracy: 0.5632\n",
            "Epoch 116/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5977 - accuracy: 0.7746 - val_loss: 1.0845 - val_accuracy: 0.5561\n",
            "Epoch 117/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6086 - accuracy: 0.7714 - val_loss: 1.0726 - val_accuracy: 0.5567\n",
            "Epoch 118/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5718 - accuracy: 0.7851 - val_loss: 1.0775 - val_accuracy: 0.5626\n",
            "Epoch 119/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6002 - accuracy: 0.7662 - val_loss: 1.0738 - val_accuracy: 0.5579\n",
            "Epoch 120/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5848 - accuracy: 0.7835 - val_loss: 1.0664 - val_accuracy: 0.5680\n",
            "Epoch 121/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5826 - accuracy: 0.7725 - val_loss: 1.0770 - val_accuracy: 0.5597\n",
            "Epoch 122/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5651 - accuracy: 0.7928 - val_loss: 1.0791 - val_accuracy: 0.5597\n",
            "Epoch 123/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5597 - accuracy: 0.7914 - val_loss: 1.0635 - val_accuracy: 0.5668\n",
            "Epoch 124/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5389 - accuracy: 0.7989 - val_loss: 1.0688 - val_accuracy: 0.5591\n",
            "Epoch 125/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5437 - accuracy: 0.7955 - val_loss: 1.0773 - val_accuracy: 0.5597\n",
            "Epoch 126/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5458 - accuracy: 0.7931 - val_loss: 1.0745 - val_accuracy: 0.5615\n",
            "Epoch 127/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5196 - accuracy: 0.8052 - val_loss: 1.0865 - val_accuracy: 0.5597\n",
            "Epoch 128/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4999 - accuracy: 0.8218 - val_loss: 1.0817 - val_accuracy: 0.5668\n",
            "Epoch 129/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5105 - accuracy: 0.8105 - val_loss: 1.0709 - val_accuracy: 0.5638\n",
            "Epoch 130/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4990 - accuracy: 0.8151 - val_loss: 1.0708 - val_accuracy: 0.5715\n",
            "Epoch 131/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5017 - accuracy: 0.8174 - val_loss: 1.0772 - val_accuracy: 0.5715\n",
            "Epoch 132/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5049 - accuracy: 0.8232 - val_loss: 1.0790 - val_accuracy: 0.5727\n",
            "Epoch 133/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4922 - accuracy: 0.8215 - val_loss: 1.0738 - val_accuracy: 0.5757\n",
            "Epoch 134/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4668 - accuracy: 0.8199 - val_loss: 1.0682 - val_accuracy: 0.5774\n",
            "Epoch 135/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4895 - accuracy: 0.8160 - val_loss: 1.0735 - val_accuracy: 0.5656\n",
            "Epoch 136/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4632 - accuracy: 0.8360 - val_loss: 1.0644 - val_accuracy: 0.5691\n",
            "Epoch 137/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4729 - accuracy: 0.8285 - val_loss: 1.0563 - val_accuracy: 0.5762\n",
            "Epoch 138/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4443 - accuracy: 0.8296 - val_loss: 1.0819 - val_accuracy: 0.5662\n",
            "Epoch 139/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4706 - accuracy: 0.8285 - val_loss: 1.0870 - val_accuracy: 0.5632\n",
            "Epoch 140/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4475 - accuracy: 0.8437 - val_loss: 1.0664 - val_accuracy: 0.5739\n",
            "Epoch 141/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4576 - accuracy: 0.8343 - val_loss: 1.0563 - val_accuracy: 0.5804\n",
            "Epoch 142/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4255 - accuracy: 0.8459 - val_loss: 1.0776 - val_accuracy: 0.5786\n",
            "Epoch 143/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4320 - accuracy: 0.8501 - val_loss: 1.0541 - val_accuracy: 0.5857\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4245 - accuracy: 0.8482 - val_loss: 1.0739 - val_accuracy: 0.5774\n",
            "Epoch 145/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3926 - accuracy: 0.8592 - val_loss: 1.0945 - val_accuracy: 0.5739\n",
            "Epoch 146/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4145 - accuracy: 0.8463 - val_loss: 1.0842 - val_accuracy: 0.5733\n",
            "Epoch 147/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4063 - accuracy: 0.8604 - val_loss: 1.0821 - val_accuracy: 0.5804\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4031 - accuracy: 0.8534 - val_loss: 1.0704 - val_accuracy: 0.5827\n",
            "Epoch 149/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3969 - accuracy: 0.8590 - val_loss: 1.0945 - val_accuracy: 0.5727\n",
            "Epoch 150/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3891 - accuracy: 0.8585 - val_loss: 1.0957 - val_accuracy: 0.5857\n",
            "Epoch 151/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3974 - accuracy: 0.8554 - val_loss: 1.0879 - val_accuracy: 0.5839\n",
            "Epoch 152/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3735 - accuracy: 0.8671 - val_loss: 1.0868 - val_accuracy: 0.5798\n",
            "Epoch 153/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3808 - accuracy: 0.8719 - val_loss: 1.0963 - val_accuracy: 0.5845\n",
            "Epoch 154/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 1.0740 - val_accuracy: 0.5816\n",
            "Epoch 155/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3699 - accuracy: 0.8717 - val_loss: 1.0875 - val_accuracy: 0.5881\n",
            "Epoch 156/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3580 - accuracy: 0.8802 - val_loss: 1.0756 - val_accuracy: 0.5898\n",
            "Epoch 157/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3551 - accuracy: 0.8792 - val_loss: 1.0744 - val_accuracy: 0.5863\n",
            "Epoch 158/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3530 - accuracy: 0.8764 - val_loss: 1.0680 - val_accuracy: 0.5792\n",
            "\n",
            "Epoch 00158: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 159/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3595 - accuracy: 0.8781 - val_loss: 1.0879 - val_accuracy: 0.5833\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3484 - accuracy: 0.8803 - val_loss: 1.0669 - val_accuracy: 0.5898\n",
            "Epoch 161/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3434 - accuracy: 0.8832 - val_loss: 1.0703 - val_accuracy: 0.5957\n",
            "Epoch 162/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3457 - accuracy: 0.8839 - val_loss: 1.0787 - val_accuracy: 0.5881\n",
            "Epoch 163/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3274 - accuracy: 0.8908 - val_loss: 1.0714 - val_accuracy: 0.5922\n",
            "Epoch 164/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.3449 - accuracy: 0.8765 - val_loss: 1.0781 - val_accuracy: 0.5875\n",
            "Epoch 165/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3251 - accuracy: 0.8855 - val_loss: 1.0665 - val_accuracy: 0.5975\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3173 - accuracy: 0.8960 - val_loss: 1.0849 - val_accuracy: 0.5804\n",
            "Epoch 167/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3453 - accuracy: 0.8761 - val_loss: 1.0831 - val_accuracy: 0.5875\n",
            "Epoch 168/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3167 - accuracy: 0.8925 - val_loss: 1.0802 - val_accuracy: 0.5810\n",
            "Epoch 169/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3322 - accuracy: 0.8885 - val_loss: 1.0871 - val_accuracy: 0.5822\n",
            "Epoch 170/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3064 - accuracy: 0.8961 - val_loss: 1.0738 - val_accuracy: 0.5946\n",
            "Epoch 171/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3282 - accuracy: 0.8898 - val_loss: 1.0813 - val_accuracy: 0.5863\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3222 - accuracy: 0.8858 - val_loss: 1.0713 - val_accuracy: 0.5916\n",
            "Epoch 173/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3325 - accuracy: 0.8893 - val_loss: 1.0656 - val_accuracy: 0.5898\n",
            "\n",
            "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 174/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3197 - accuracy: 0.8913 - val_loss: 1.0696 - val_accuracy: 0.5887\n",
            "Epoch 175/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3071 - accuracy: 0.8999 - val_loss: 1.0620 - val_accuracy: 0.5892\n",
            "Epoch 176/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3086 - accuracy: 0.8930 - val_loss: 1.0683 - val_accuracy: 0.5934\n",
            "Epoch 177/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3122 - accuracy: 0.8989 - val_loss: 1.0712 - val_accuracy: 0.5916\n",
            "Epoch 178/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3101 - accuracy: 0.8984 - val_loss: 1.0716 - val_accuracy: 0.5869\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3216 - accuracy: 0.8914 - val_loss: 1.0586 - val_accuracy: 0.5928\n",
            "Epoch 180/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3010 - accuracy: 0.9048 - val_loss: 1.0655 - val_accuracy: 0.5898\n",
            "Epoch 181/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3100 - accuracy: 0.9003 - val_loss: 1.0557 - val_accuracy: 0.5952\n",
            "Epoch 182/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3199 - accuracy: 0.8977 - val_loss: 1.0571 - val_accuracy: 0.5916\n",
            "Epoch 183/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3272 - accuracy: 0.8901 - val_loss: 1.0566 - val_accuracy: 0.5987\n",
            "Epoch 184/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3172 - accuracy: 0.8984 - val_loss: 1.0497 - val_accuracy: 0.5957\n",
            "Epoch 185/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2991 - accuracy: 0.9055 - val_loss: 1.0579 - val_accuracy: 0.5904\n",
            "Epoch 186/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3180 - accuracy: 0.8998 - val_loss: 1.0508 - val_accuracy: 0.5975\n",
            "Epoch 187/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3093 - accuracy: 0.9022 - val_loss: 1.0507 - val_accuracy: 0.5993\n",
            "Epoch 188/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3112 - accuracy: 0.9023 - val_loss: 1.0420 - val_accuracy: 0.5963\n",
            "Epoch 189/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3110 - accuracy: 0.9007 - val_loss: 1.0478 - val_accuracy: 0.5910\n",
            "Epoch 190/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3015 - accuracy: 0.9062 - val_loss: 1.0454 - val_accuracy: 0.5952\n",
            "Epoch 191/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3060 - accuracy: 0.9031 - val_loss: 1.0335 - val_accuracy: 0.5993\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3146 - accuracy: 0.9019 - val_loss: 1.0401 - val_accuracy: 0.5957\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3137 - accuracy: 0.8952 - val_loss: 1.0409 - val_accuracy: 0.5922\n",
            "Epoch 194/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.2999 - accuracy: 0.8990 - val_loss: 1.0379 - val_accuracy: 0.5963\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3155 - accuracy: 0.9017 - val_loss: 1.0463 - val_accuracy: 0.5969\n",
            "Epoch 196/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3146 - accuracy: 0.8988 - val_loss: 1.0330 - val_accuracy: 0.5975\n",
            "Epoch 197/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3021 - accuracy: 0.9019 - val_loss: 1.0275 - val_accuracy: 0.5969\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2939 - accuracy: 0.9067 - val_loss: 1.0397 - val_accuracy: 0.5946\n",
            "Epoch 199/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3078 - accuracy: 0.9069 - val_loss: 1.0323 - val_accuracy: 0.5946\n",
            "Epoch 200/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3015 - accuracy: 0.9055 - val_loss: 1.0316 - val_accuracy: 0.5910\n",
            "Epoch 201/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3225 - accuracy: 0.8919 - val_loss: 1.0331 - val_accuracy: 0.5952\n",
            "Epoch 202/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3191 - accuracy: 0.8973 - val_loss: 1.0276 - val_accuracy: 0.5934\n",
            "Epoch 203/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3159 - accuracy: 0.9010 - val_loss: 1.0354 - val_accuracy: 0.5957\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2990 - accuracy: 0.8997 - val_loss: 1.0239 - val_accuracy: 0.5969\n",
            "Epoch 205/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3065 - accuracy: 0.8981 - val_loss: 1.0310 - val_accuracy: 0.5963\n",
            "Epoch 206/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3042 - accuracy: 0.9061 - val_loss: 1.0250 - val_accuracy: 0.5987\n",
            "Epoch 207/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3019 - accuracy: 0.9104 - val_loss: 1.0255 - val_accuracy: 0.5952\n",
            "Epoch 208/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3072 - accuracy: 0.9036 - val_loss: 1.0165 - val_accuracy: 0.5987\n",
            "Epoch 209/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3266 - accuracy: 0.8915 - val_loss: 1.0191 - val_accuracy: 0.5999\n",
            "Epoch 210/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3056 - accuracy: 0.9034 - val_loss: 1.0266 - val_accuracy: 0.6022\n",
            "Epoch 211/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2974 - accuracy: 0.9111 - val_loss: 1.0259 - val_accuracy: 0.5975\n",
            "Epoch 212/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3056 - accuracy: 0.9018 - val_loss: 1.0152 - val_accuracy: 0.6028\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2999 - accuracy: 0.9041 - val_loss: 1.0219 - val_accuracy: 0.6005\n",
            "Epoch 214/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2972 - accuracy: 0.9095 - val_loss: 1.0155 - val_accuracy: 0.6005\n",
            "Epoch 215/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3070 - accuracy: 0.9026 - val_loss: 1.0060 - val_accuracy: 0.6093\n",
            "Epoch 216/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3094 - accuracy: 0.9008 - val_loss: 1.0089 - val_accuracy: 0.6046\n",
            "Epoch 217/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3103 - accuracy: 0.9010 - val_loss: 1.0210 - val_accuracy: 0.6011\n",
            "Epoch 218/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2976 - accuracy: 0.9010 - val_loss: 1.0125 - val_accuracy: 0.5999\n",
            "Epoch 219/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3126 - accuracy: 0.9033 - val_loss: 1.0125 - val_accuracy: 0.5999\n",
            "Epoch 220/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3147 - accuracy: 0.9011 - val_loss: 1.0169 - val_accuracy: 0.5946\n",
            "Epoch 221/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2965 - accuracy: 0.9113 - val_loss: 1.0123 - val_accuracy: 0.6052\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2985 - accuracy: 0.9107 - val_loss: 1.0140 - val_accuracy: 0.6011\n",
            "Epoch 223/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3091 - accuracy: 0.9073 - val_loss: 1.0103 - val_accuracy: 0.6076\n",
            "Epoch 224/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2926 - accuracy: 0.9094 - val_loss: 1.0223 - val_accuracy: 0.6017\n",
            "Epoch 225/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2975 - accuracy: 0.9090 - val_loss: 1.0177 - val_accuracy: 0.5993\n",
            "Epoch 226/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3022 - accuracy: 0.9046 - val_loss: 1.0082 - val_accuracy: 0.6005\n",
            "Epoch 227/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3199 - accuracy: 0.8977 - val_loss: 1.0069 - val_accuracy: 0.6058\n",
            "Epoch 228/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3126 - accuracy: 0.8993 - val_loss: 1.0044 - val_accuracy: 0.6058\n",
            "Epoch 229/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3079 - accuracy: 0.9042 - val_loss: 1.0089 - val_accuracy: 0.6076\n",
            "Epoch 230/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3052 - accuracy: 0.9104 - val_loss: 1.0033 - val_accuracy: 0.6011\n",
            "Epoch 231/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3053 - accuracy: 0.9044 - val_loss: 1.0070 - val_accuracy: 0.6076\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 0.2948 - accuracy: 0.9120 - val_loss: 1.0000 - val_accuracy: 0.6064\n",
            "Epoch 233/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3103 - accuracy: 0.9028 - val_loss: 1.0054 - val_accuracy: 0.6011\n",
            "Epoch 234/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3086 - accuracy: 0.9015 - val_loss: 1.0107 - val_accuracy: 0.6022\n",
            "Epoch 235/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3131 - accuracy: 0.9014 - val_loss: 1.0062 - val_accuracy: 0.6034\n",
            "Epoch 236/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3156 - accuracy: 0.9002 - val_loss: 0.9933 - val_accuracy: 0.6099\n",
            "Epoch 237/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3081 - accuracy: 0.9059 - val_loss: 1.0026 - val_accuracy: 0.6052\n",
            "Epoch 238/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2966 - accuracy: 0.9131 - val_loss: 1.0001 - val_accuracy: 0.6052\n",
            "Epoch 239/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3039 - accuracy: 0.9086 - val_loss: 1.0053 - val_accuracy: 0.6058\n",
            "Epoch 240/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3063 - accuracy: 0.9035 - val_loss: 1.0031 - val_accuracy: 0.6034\n",
            "Epoch 241/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3136 - accuracy: 0.8996 - val_loss: 0.9955 - val_accuracy: 0.6052\n",
            "Epoch 242/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3079 - accuracy: 0.9049 - val_loss: 1.0015 - val_accuracy: 0.6005\n",
            "Epoch 243/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2946 - accuracy: 0.9073 - val_loss: 0.9974 - val_accuracy: 0.6052\n",
            "Epoch 244/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3096 - accuracy: 0.9025 - val_loss: 0.9953 - val_accuracy: 0.6064\n",
            "Epoch 245/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3055 - accuracy: 0.9054 - val_loss: 0.9867 - val_accuracy: 0.6123\n",
            "Epoch 246/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3077 - accuracy: 0.9052 - val_loss: 1.0031 - val_accuracy: 0.6111\n",
            "Epoch 247/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3038 - accuracy: 0.9103 - val_loss: 0.9973 - val_accuracy: 0.6105\n",
            "Epoch 248/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.2908 - accuracy: 0.9142 - val_loss: 0.9959 - val_accuracy: 0.6099\n",
            "Epoch 249/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3001 - accuracy: 0.9113 - val_loss: 0.9975 - val_accuracy: 0.6135\n",
            "Epoch 250/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3077 - accuracy: 0.9034 - val_loss: 0.9890 - val_accuracy: 0.6123\n",
            "Epoch 251/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2950 - accuracy: 0.9121 - val_loss: 0.9921 - val_accuracy: 0.6082\n",
            "Epoch 252/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2946 - accuracy: 0.9057 - val_loss: 0.9935 - val_accuracy: 0.6105\n",
            "Epoch 253/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3154 - accuracy: 0.8986 - val_loss: 0.9899 - val_accuracy: 0.6105\n",
            "Epoch 254/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3073 - accuracy: 0.9085 - val_loss: 0.9896 - val_accuracy: 0.6141\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3005 - accuracy: 0.9043 - val_loss: 0.9964 - val_accuracy: 0.6093\n",
            "Epoch 256/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.2915 - accuracy: 0.9181 - val_loss: 0.9945 - val_accuracy: 0.6064\n",
            "Epoch 257/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3108 - accuracy: 0.9055 - val_loss: 0.9891 - val_accuracy: 0.6099\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3026 - accuracy: 0.9021 - val_loss: 0.9830 - val_accuracy: 0.6129\n",
            "Epoch 259/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3024 - accuracy: 0.9064 - val_loss: 0.9930 - val_accuracy: 0.6129\n",
            "Epoch 260/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3052 - accuracy: 0.9029 - val_loss: 0.9922 - val_accuracy: 0.6117\n",
            "Epoch 261/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2953 - accuracy: 0.9123 - val_loss: 0.9933 - val_accuracy: 0.6105\n",
            "Epoch 262/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3081 - accuracy: 0.8991 - val_loss: 0.9803 - val_accuracy: 0.6170\n",
            "Epoch 263/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3158 - accuracy: 0.8967 - val_loss: 0.9982 - val_accuracy: 0.6070\n",
            "Epoch 264/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2978 - accuracy: 0.9096 - val_loss: 0.9923 - val_accuracy: 0.6093\n",
            "Epoch 265/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3142 - accuracy: 0.9007 - val_loss: 0.9887 - val_accuracy: 0.6152\n",
            "Epoch 266/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3133 - accuracy: 0.8996 - val_loss: 0.9926 - val_accuracy: 0.6099\n",
            "Epoch 267/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3167 - accuracy: 0.9041 - val_loss: 0.9808 - val_accuracy: 0.6194\n",
            "Epoch 268/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2972 - accuracy: 0.9143 - val_loss: 0.9862 - val_accuracy: 0.6141\n",
            "Epoch 269/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3166 - accuracy: 0.8989 - val_loss: 0.9788 - val_accuracy: 0.6206\n",
            "Epoch 270/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2939 - accuracy: 0.9103 - val_loss: 0.9912 - val_accuracy: 0.6064\n",
            "Epoch 271/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2946 - accuracy: 0.9113 - val_loss: 0.9863 - val_accuracy: 0.6117\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3018 - accuracy: 0.9094 - val_loss: 0.9906 - val_accuracy: 0.6105\n",
            "Epoch 273/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3027 - accuracy: 0.9087 - val_loss: 0.9941 - val_accuracy: 0.6152\n",
            "Epoch 274/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2933 - accuracy: 0.9168 - val_loss: 0.9846 - val_accuracy: 0.6147\n",
            "Epoch 275/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3048 - accuracy: 0.9055 - val_loss: 0.9838 - val_accuracy: 0.6182\n",
            "Epoch 276/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3171 - accuracy: 0.8962 - val_loss: 0.9921 - val_accuracy: 0.6111\n",
            "Epoch 277/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2952 - accuracy: 0.9127 - val_loss: 0.9870 - val_accuracy: 0.6117\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3125 - accuracy: 0.9081 - val_loss: 0.9863 - val_accuracy: 0.6076\n",
            "Epoch 279/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2925 - accuracy: 0.9090 - val_loss: 0.9820 - val_accuracy: 0.6152\n",
            "Epoch 280/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3147 - accuracy: 0.9022 - val_loss: 0.9722 - val_accuracy: 0.6158\n",
            "Epoch 281/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2973 - accuracy: 0.9122 - val_loss: 0.9825 - val_accuracy: 0.6158\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3031 - accuracy: 0.9127 - val_loss: 0.9808 - val_accuracy: 0.6158\n",
            "Epoch 283/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2959 - accuracy: 0.9147 - val_loss: 0.9781 - val_accuracy: 0.6176\n",
            "Epoch 284/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2949 - accuracy: 0.9062 - val_loss: 0.9749 - val_accuracy: 0.6152\n",
            "Epoch 285/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2923 - accuracy: 0.9164 - val_loss: 0.9790 - val_accuracy: 0.6158\n",
            "Epoch 286/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3048 - accuracy: 0.9072 - val_loss: 0.9788 - val_accuracy: 0.6170\n",
            "Epoch 287/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3075 - accuracy: 0.9047 - val_loss: 0.9736 - val_accuracy: 0.6147\n",
            "Epoch 288/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3092 - accuracy: 0.9027 - val_loss: 0.9847 - val_accuracy: 0.6123\n",
            "Epoch 289/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2953 - accuracy: 0.9176 - val_loss: 0.9813 - val_accuracy: 0.6099\n",
            "Epoch 290/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2948 - accuracy: 0.9054 - val_loss: 0.9757 - val_accuracy: 0.6147\n",
            "Epoch 291/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3079 - accuracy: 0.9052 - val_loss: 0.9783 - val_accuracy: 0.6158\n",
            "Epoch 292/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2913 - accuracy: 0.9112 - val_loss: 0.9810 - val_accuracy: 0.6223\n",
            "Epoch 293/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2923 - accuracy: 0.9096 - val_loss: 0.9806 - val_accuracy: 0.6188\n",
            "Epoch 294/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2924 - accuracy: 0.9108 - val_loss: 0.9713 - val_accuracy: 0.6212\n",
            "Epoch 295/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3014 - accuracy: 0.9087 - val_loss: 0.9802 - val_accuracy: 0.6158\n",
            "Epoch 296/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3036 - accuracy: 0.9039 - val_loss: 0.9720 - val_accuracy: 0.6200\n",
            "Epoch 297/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3012 - accuracy: 0.9027 - val_loss: 0.9750 - val_accuracy: 0.6141\n",
            "Epoch 298/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2993 - accuracy: 0.9075 - val_loss: 0.9759 - val_accuracy: 0.6206\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3113 - accuracy: 0.9059 - val_loss: 0.9772 - val_accuracy: 0.6212\n",
            "Epoch 300/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2950 - accuracy: 0.9091 - val_loss: 0.9734 - val_accuracy: 0.6147\n",
            "Epoch 301/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2923 - accuracy: 0.9157 - val_loss: 0.9726 - val_accuracy: 0.6217\n",
            "Epoch 302/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3034 - accuracy: 0.9077 - val_loss: 0.9755 - val_accuracy: 0.6176\n",
            "Epoch 303/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3085 - accuracy: 0.9006 - val_loss: 0.9786 - val_accuracy: 0.6152\n",
            "Epoch 304/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3005 - accuracy: 0.9106 - val_loss: 0.9747 - val_accuracy: 0.6212\n",
            "Epoch 305/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3027 - accuracy: 0.9073 - val_loss: 0.9869 - val_accuracy: 0.6158\n",
            "Epoch 306/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3021 - accuracy: 0.9038 - val_loss: 0.9727 - val_accuracy: 0.6182\n",
            "Epoch 307/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3008 - accuracy: 0.9087 - val_loss: 0.9851 - val_accuracy: 0.6135\n",
            "Epoch 308/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2917 - accuracy: 0.9157 - val_loss: 0.9676 - val_accuracy: 0.6223\n",
            "Epoch 309/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2905 - accuracy: 0.9147 - val_loss: 0.9752 - val_accuracy: 0.6188\n",
            "Epoch 310/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2947 - accuracy: 0.9126 - val_loss: 0.9715 - val_accuracy: 0.6158\n",
            "Epoch 311/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2876 - accuracy: 0.9163 - val_loss: 0.9721 - val_accuracy: 0.6241\n",
            "Epoch 312/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3011 - accuracy: 0.9078 - val_loss: 0.9711 - val_accuracy: 0.6135\n",
            "Epoch 313/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3074 - accuracy: 0.9038 - val_loss: 0.9725 - val_accuracy: 0.6212\n",
            "Epoch 314/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2958 - accuracy: 0.9088 - val_loss: 0.9658 - val_accuracy: 0.6206\n",
            "Epoch 315/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2913 - accuracy: 0.9157 - val_loss: 0.9669 - val_accuracy: 0.6217\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2992 - accuracy: 0.9135 - val_loss: 0.9672 - val_accuracy: 0.6259\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2848 - accuracy: 0.9205 - val_loss: 0.9742 - val_accuracy: 0.6158\n",
            "Epoch 318/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2999 - accuracy: 0.9130 - val_loss: 0.9671 - val_accuracy: 0.6277\n",
            "Epoch 319/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2846 - accuracy: 0.9161 - val_loss: 0.9648 - val_accuracy: 0.6294\n",
            "Epoch 320/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2965 - accuracy: 0.9100 - val_loss: 0.9682 - val_accuracy: 0.6241\n",
            "Epoch 321/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2866 - accuracy: 0.9134 - val_loss: 0.9618 - val_accuracy: 0.6217\n",
            "Epoch 322/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2950 - accuracy: 0.9139 - val_loss: 0.9791 - val_accuracy: 0.6176\n",
            "Epoch 323/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2953 - accuracy: 0.9062 - val_loss: 0.9616 - val_accuracy: 0.6235\n",
            "Epoch 324/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2994 - accuracy: 0.9132 - val_loss: 0.9625 - val_accuracy: 0.6247\n",
            "Epoch 325/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2944 - accuracy: 0.9126 - val_loss: 0.9708 - val_accuracy: 0.6265\n",
            "Epoch 326/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2960 - accuracy: 0.9108 - val_loss: 0.9677 - val_accuracy: 0.6253\n",
            "Epoch 327/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2956 - accuracy: 0.9118 - val_loss: 0.9719 - val_accuracy: 0.6265\n",
            "Epoch 328/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2886 - accuracy: 0.9153 - val_loss: 0.9754 - val_accuracy: 0.6212\n",
            "Epoch 329/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2939 - accuracy: 0.9131 - val_loss: 0.9574 - val_accuracy: 0.6223\n",
            "Epoch 330/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2855 - accuracy: 0.9176 - val_loss: 0.9688 - val_accuracy: 0.6229\n",
            "Epoch 331/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2985 - accuracy: 0.9103 - val_loss: 0.9619 - val_accuracy: 0.6182\n",
            "Epoch 332/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2937 - accuracy: 0.9147 - val_loss: 0.9714 - val_accuracy: 0.6194\n",
            "Epoch 333/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2875 - accuracy: 0.9163 - val_loss: 0.9603 - val_accuracy: 0.6265\n",
            "Epoch 334/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2886 - accuracy: 0.9126 - val_loss: 0.9655 - val_accuracy: 0.6217\n",
            "Epoch 335/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3005 - accuracy: 0.9083 - val_loss: 0.9703 - val_accuracy: 0.6212\n",
            "Epoch 336/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2938 - accuracy: 0.9139 - val_loss: 0.9665 - val_accuracy: 0.6241\n",
            "Epoch 337/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2822 - accuracy: 0.9184 - val_loss: 0.9675 - val_accuracy: 0.6253\n",
            "Epoch 338/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2928 - accuracy: 0.9129 - val_loss: 0.9684 - val_accuracy: 0.6170\n",
            "Epoch 339/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2923 - accuracy: 0.9125 - val_loss: 0.9501 - val_accuracy: 0.6212\n",
            "Epoch 340/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2991 - accuracy: 0.9095 - val_loss: 0.9575 - val_accuracy: 0.6265\n",
            "Epoch 341/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2895 - accuracy: 0.9135 - val_loss: 0.9672 - val_accuracy: 0.6294\n",
            "Epoch 342/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2942 - accuracy: 0.9116 - val_loss: 0.9587 - val_accuracy: 0.6277\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.2911 - accuracy: 0.9161 - val_loss: 0.9579 - val_accuracy: 0.6259\n",
            "Epoch 344/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.2912 - accuracy: 0.9086 - val_loss: 0.9608 - val_accuracy: 0.6324\n",
            "Epoch 345/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.2876 - accuracy: 0.9142 - val_loss: 0.9626 - val_accuracy: 0.6235\n",
            "Epoch 346/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2862 - accuracy: 0.9161 - val_loss: 0.9671 - val_accuracy: 0.6194\n",
            "Epoch 347/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3019 - accuracy: 0.9086 - val_loss: 0.9558 - val_accuracy: 0.6247\n",
            "Epoch 348/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.2922 - accuracy: 0.9120 - val_loss: 0.9714 - val_accuracy: 0.6306\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2847 - accuracy: 0.9144 - val_loss: 0.9650 - val_accuracy: 0.6294\n",
            "Epoch 350/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2867 - accuracy: 0.9161 - val_loss: 0.9677 - val_accuracy: 0.6188\n",
            "Epoch 351/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2773 - accuracy: 0.9131 - val_loss: 0.9653 - val_accuracy: 0.6259\n",
            "Epoch 352/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2867 - accuracy: 0.9183 - val_loss: 0.9602 - val_accuracy: 0.6247\n",
            "Epoch 353/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2888 - accuracy: 0.9137 - val_loss: 0.9648 - val_accuracy: 0.6188\n",
            "Epoch 354/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3023 - accuracy: 0.9143 - val_loss: 0.9517 - val_accuracy: 0.6288\n",
            "\n",
            "Epoch 00354: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 355/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3013 - accuracy: 0.9120 - val_loss: 0.9715 - val_accuracy: 0.6259\n",
            "Epoch 356/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2916 - accuracy: 0.9153 - val_loss: 0.9671 - val_accuracy: 0.6212\n",
            "Epoch 357/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2933 - accuracy: 0.9125 - val_loss: 0.9646 - val_accuracy: 0.6259\n",
            "Epoch 358/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2907 - accuracy: 0.9174 - val_loss: 0.9522 - val_accuracy: 0.6253\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3005 - accuracy: 0.9084 - val_loss: 0.9574 - val_accuracy: 0.6229\n",
            "Epoch 360/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2953 - accuracy: 0.9130 - val_loss: 0.9567 - val_accuracy: 0.6288\n",
            "Epoch 361/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2910 - accuracy: 0.9145 - val_loss: 0.9508 - val_accuracy: 0.6271\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2816 - accuracy: 0.9154 - val_loss: 0.9448 - val_accuracy: 0.6247\n",
            "Epoch 363/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2870 - accuracy: 0.9203 - val_loss: 0.9535 - val_accuracy: 0.6188\n",
            "Epoch 364/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2851 - accuracy: 0.9240 - val_loss: 0.9481 - val_accuracy: 0.6277\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.2935 - accuracy: 0.9205 - val_loss: 0.9486 - val_accuracy: 0.6253\n",
            "Epoch 366/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3004 - accuracy: 0.9112 - val_loss: 0.9448 - val_accuracy: 0.6271\n",
            "Epoch 367/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3002 - accuracy: 0.9064 - val_loss: 0.9454 - val_accuracy: 0.6330\n",
            "Epoch 368/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3111 - accuracy: 0.9096 - val_loss: 0.9391 - val_accuracy: 0.6318\n",
            "Epoch 369/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3012 - accuracy: 0.9153 - val_loss: 0.9396 - val_accuracy: 0.6342\n",
            "Epoch 370/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.2976 - accuracy: 0.9162 - val_loss: 0.9450 - val_accuracy: 0.6300\n",
            "Epoch 371/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3082 - accuracy: 0.9100 - val_loss: 0.9452 - val_accuracy: 0.6283\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3083 - accuracy: 0.9072 - val_loss: 0.9382 - val_accuracy: 0.6288\n",
            "Epoch 373/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3133 - accuracy: 0.9134 - val_loss: 0.9428 - val_accuracy: 0.6365\n",
            "Epoch 374/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3087 - accuracy: 0.9109 - val_loss: 0.9389 - val_accuracy: 0.6330\n",
            "Epoch 375/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3165 - accuracy: 0.9019 - val_loss: 0.9401 - val_accuracy: 0.6253\n",
            "Epoch 376/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3106 - accuracy: 0.9140 - val_loss: 0.9376 - val_accuracy: 0.6342\n",
            "Epoch 377/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3107 - accuracy: 0.9100 - val_loss: 0.9316 - val_accuracy: 0.6318\n",
            "Epoch 378/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3047 - accuracy: 0.9216 - val_loss: 0.9312 - val_accuracy: 0.6312\n",
            "Epoch 379/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3219 - accuracy: 0.9032 - val_loss: 0.9389 - val_accuracy: 0.6312\n",
            "Epoch 380/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3209 - accuracy: 0.9078 - val_loss: 0.9379 - val_accuracy: 0.6271\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3304 - accuracy: 0.9031 - val_loss: 0.9353 - val_accuracy: 0.6271\n",
            "Epoch 382/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3196 - accuracy: 0.9078 - val_loss: 0.9309 - val_accuracy: 0.6271\n",
            "Epoch 383/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3097 - accuracy: 0.9155 - val_loss: 0.9360 - val_accuracy: 0.6336\n",
            "Epoch 384/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3196 - accuracy: 0.9139 - val_loss: 0.9287 - val_accuracy: 0.6306\n",
            "Epoch 385/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3233 - accuracy: 0.9094 - val_loss: 0.9333 - val_accuracy: 0.6294\n",
            "Epoch 386/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3261 - accuracy: 0.9064 - val_loss: 0.9288 - val_accuracy: 0.6336\n",
            "Epoch 387/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3155 - accuracy: 0.9181 - val_loss: 0.9267 - val_accuracy: 0.6324\n",
            "Epoch 388/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3290 - accuracy: 0.9051 - val_loss: 0.9259 - val_accuracy: 0.6312\n",
            "Epoch 389/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3376 - accuracy: 0.9059 - val_loss: 0.9270 - val_accuracy: 0.6306\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3274 - accuracy: 0.9089 - val_loss: 0.9344 - val_accuracy: 0.6294\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3290 - accuracy: 0.9049 - val_loss: 0.9311 - val_accuracy: 0.6283\n",
            "Epoch 392/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3316 - accuracy: 0.9080 - val_loss: 0.9281 - val_accuracy: 0.6306\n",
            "Epoch 393/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3300 - accuracy: 0.9054 - val_loss: 0.9301 - val_accuracy: 0.6336\n",
            "Epoch 394/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3295 - accuracy: 0.9051 - val_loss: 0.9270 - val_accuracy: 0.6324\n",
            "Epoch 395/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3363 - accuracy: 0.9063 - val_loss: 0.9256 - val_accuracy: 0.6336\n",
            "Epoch 396/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3263 - accuracy: 0.9109 - val_loss: 0.9339 - val_accuracy: 0.6330\n",
            "Epoch 397/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3370 - accuracy: 0.9033 - val_loss: 0.9221 - val_accuracy: 0.6371\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3281 - accuracy: 0.9084 - val_loss: 0.9196 - val_accuracy: 0.6336\n",
            "Epoch 399/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3356 - accuracy: 0.9029 - val_loss: 0.9292 - val_accuracy: 0.6294\n",
            "Epoch 400/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3347 - accuracy: 0.9028 - val_loss: 0.9236 - val_accuracy: 0.6353\n",
            "Epoch 401/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3261 - accuracy: 0.9128 - val_loss: 0.9189 - val_accuracy: 0.6306\n",
            "Epoch 402/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3424 - accuracy: 0.9033 - val_loss: 0.9186 - val_accuracy: 0.6312\n",
            "Epoch 403/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3425 - accuracy: 0.9070 - val_loss: 0.9245 - val_accuracy: 0.6318\n",
            "Epoch 404/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3361 - accuracy: 0.9044 - val_loss: 0.9237 - val_accuracy: 0.6330\n",
            "Epoch 405/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3326 - accuracy: 0.9084 - val_loss: 0.9214 - val_accuracy: 0.6342\n",
            "Epoch 406/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3358 - accuracy: 0.9048 - val_loss: 0.9255 - val_accuracy: 0.6306\n",
            "Epoch 407/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3397 - accuracy: 0.9069 - val_loss: 0.9240 - val_accuracy: 0.6371\n",
            "Epoch 408/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3426 - accuracy: 0.9027 - val_loss: 0.9221 - val_accuracy: 0.6401\n",
            "Epoch 409/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3459 - accuracy: 0.9014 - val_loss: 0.9280 - val_accuracy: 0.6306\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3465 - accuracy: 0.9061 - val_loss: 0.9215 - val_accuracy: 0.6348\n",
            "Epoch 411/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3568 - accuracy: 0.8976 - val_loss: 0.9268 - val_accuracy: 0.6312\n",
            "Epoch 412/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3566 - accuracy: 0.8982 - val_loss: 0.9218 - val_accuracy: 0.6300\n",
            "Epoch 413/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3407 - accuracy: 0.9030 - val_loss: 0.9265 - val_accuracy: 0.6324\n",
            "Epoch 414/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3384 - accuracy: 0.9022 - val_loss: 0.9249 - val_accuracy: 0.6330\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3520 - accuracy: 0.9033 - val_loss: 0.9193 - val_accuracy: 0.6348\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3487 - accuracy: 0.9069 - val_loss: 0.9188 - val_accuracy: 0.6324\n",
            "Epoch 417/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3465 - accuracy: 0.9055 - val_loss: 0.9189 - val_accuracy: 0.6300\n",
            "\n",
            "Epoch 00417: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 418/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3494 - accuracy: 0.8998 - val_loss: 0.9212 - val_accuracy: 0.6330\n",
            "Epoch 419/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3360 - accuracy: 0.9090 - val_loss: 0.9193 - val_accuracy: 0.6348\n",
            "Epoch 420/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3578 - accuracy: 0.9035 - val_loss: 0.9173 - val_accuracy: 0.6359\n",
            "Epoch 421/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3586 - accuracy: 0.9022 - val_loss: 0.9165 - val_accuracy: 0.6359\n",
            "Epoch 422/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3532 - accuracy: 0.9025 - val_loss: 0.9186 - val_accuracy: 0.6342\n",
            "Epoch 423/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3572 - accuracy: 0.8988 - val_loss: 0.9156 - val_accuracy: 0.6353\n",
            "Epoch 424/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3523 - accuracy: 0.8989 - val_loss: 0.9116 - val_accuracy: 0.6395\n",
            "Epoch 425/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3584 - accuracy: 0.9027 - val_loss: 0.9175 - val_accuracy: 0.6312\n",
            "Epoch 426/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3536 - accuracy: 0.9117 - val_loss: 0.9164 - val_accuracy: 0.6336\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3608 - accuracy: 0.8965 - val_loss: 0.9116 - val_accuracy: 0.6336\n",
            "Epoch 428/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3549 - accuracy: 0.9019 - val_loss: 0.9146 - val_accuracy: 0.6353\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3712 - accuracy: 0.9026 - val_loss: 0.9123 - val_accuracy: 0.6383\n",
            "Epoch 430/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.3756 - accuracy: 0.8952 - val_loss: 0.9147 - val_accuracy: 0.6330\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3742 - accuracy: 0.9006 - val_loss: 0.9127 - val_accuracy: 0.6377\n",
            "Epoch 432/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3790 - accuracy: 0.8908 - val_loss: 0.9110 - val_accuracy: 0.6389\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3679 - accuracy: 0.9043 - val_loss: 0.9133 - val_accuracy: 0.6359\n",
            "Epoch 434/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3682 - accuracy: 0.9016 - val_loss: 0.9085 - val_accuracy: 0.6383\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3765 - accuracy: 0.8978 - val_loss: 0.9110 - val_accuracy: 0.6395\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3723 - accuracy: 0.9058 - val_loss: 0.9075 - val_accuracy: 0.6371\n",
            "Epoch 437/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3831 - accuracy: 0.8994 - val_loss: 0.9110 - val_accuracy: 0.6395\n",
            "Epoch 438/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3870 - accuracy: 0.8961 - val_loss: 0.9100 - val_accuracy: 0.6348\n",
            "Epoch 439/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3865 - accuracy: 0.8957 - val_loss: 0.9099 - val_accuracy: 0.6365\n",
            "Epoch 440/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3982 - accuracy: 0.8908 - val_loss: 0.9077 - val_accuracy: 0.6359\n",
            "Epoch 441/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3949 - accuracy: 0.8928 - val_loss: 0.9130 - val_accuracy: 0.6342\n",
            "Epoch 442/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3941 - accuracy: 0.8985 - val_loss: 0.9106 - val_accuracy: 0.6336\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3902 - accuracy: 0.8950 - val_loss: 0.9064 - val_accuracy: 0.6389\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3987 - accuracy: 0.8944 - val_loss: 0.9093 - val_accuracy: 0.6383\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3946 - accuracy: 0.9001 - val_loss: 0.9085 - val_accuracy: 0.6365\n",
            "Epoch 446/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4021 - accuracy: 0.8929 - val_loss: 0.9105 - val_accuracy: 0.6377\n",
            "Epoch 447/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3980 - accuracy: 0.8941 - val_loss: 0.9066 - val_accuracy: 0.6430\n",
            "Epoch 448/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4030 - accuracy: 0.8986 - val_loss: 0.9089 - val_accuracy: 0.6383\n",
            "Epoch 449/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4182 - accuracy: 0.8884 - val_loss: 0.9098 - val_accuracy: 0.6371\n",
            "Epoch 450/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4004 - accuracy: 0.8934 - val_loss: 0.9085 - val_accuracy: 0.6377\n",
            "Epoch 451/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4144 - accuracy: 0.8871 - val_loss: 0.9084 - val_accuracy: 0.6383\n",
            "Epoch 452/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4129 - accuracy: 0.8932 - val_loss: 0.9099 - val_accuracy: 0.6371\n",
            "Epoch 453/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4301 - accuracy: 0.8789 - val_loss: 0.9048 - val_accuracy: 0.6395\n",
            "Epoch 454/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4178 - accuracy: 0.8881 - val_loss: 0.9097 - val_accuracy: 0.6377\n",
            "Epoch 455/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4146 - accuracy: 0.8913 - val_loss: 0.9053 - val_accuracy: 0.6395\n",
            "Epoch 456/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4176 - accuracy: 0.8901 - val_loss: 0.9067 - val_accuracy: 0.6424\n",
            "Epoch 457/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4272 - accuracy: 0.8859 - val_loss: 0.9084 - val_accuracy: 0.6365\n",
            "Epoch 458/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4268 - accuracy: 0.8906 - val_loss: 0.9048 - val_accuracy: 0.6413\n",
            "Epoch 459/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4174 - accuracy: 0.8966 - val_loss: 0.9059 - val_accuracy: 0.6401\n",
            "Epoch 460/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4327 - accuracy: 0.8847 - val_loss: 0.9068 - val_accuracy: 0.6389\n",
            "Epoch 461/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4556 - accuracy: 0.8735 - val_loss: 0.9050 - val_accuracy: 0.6424\n",
            "Epoch 462/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4340 - accuracy: 0.8820 - val_loss: 0.9061 - val_accuracy: 0.6383\n",
            "Epoch 463/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4375 - accuracy: 0.8855 - val_loss: 0.9067 - val_accuracy: 0.6401\n",
            "Epoch 464/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4328 - accuracy: 0.8897 - val_loss: 0.9045 - val_accuracy: 0.6401\n",
            "Epoch 465/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4364 - accuracy: 0.8872 - val_loss: 0.9095 - val_accuracy: 0.6395\n",
            "Epoch 466/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4356 - accuracy: 0.8850 - val_loss: 0.9074 - val_accuracy: 0.6424\n",
            "Epoch 467/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4468 - accuracy: 0.8810 - val_loss: 0.9053 - val_accuracy: 0.6413\n",
            "Epoch 468/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4441 - accuracy: 0.8873 - val_loss: 0.9051 - val_accuracy: 0.6407\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4489 - accuracy: 0.8767 - val_loss: 0.9085 - val_accuracy: 0.6383\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4521 - accuracy: 0.8837 - val_loss: 0.9089 - val_accuracy: 0.6424\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4515 - accuracy: 0.8821 - val_loss: 0.9073 - val_accuracy: 0.6395\n",
            "Epoch 472/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4495 - accuracy: 0.8907 - val_loss: 0.9048 - val_accuracy: 0.6395\n",
            "Epoch 473/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4611 - accuracy: 0.8776 - val_loss: 0.9027 - val_accuracy: 0.6436\n",
            "Epoch 474/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4437 - accuracy: 0.8876 - val_loss: 0.9065 - val_accuracy: 0.6418\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4438 - accuracy: 0.8830 - val_loss: 0.9039 - val_accuracy: 0.6407\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4510 - accuracy: 0.8843 - val_loss: 0.9061 - val_accuracy: 0.6413\n",
            "Epoch 477/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4556 - accuracy: 0.8852 - val_loss: 0.9051 - val_accuracy: 0.6413\n",
            "Epoch 478/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4523 - accuracy: 0.8855 - val_loss: 0.9094 - val_accuracy: 0.6377\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4598 - accuracy: 0.8729 - val_loss: 0.9080 - val_accuracy: 0.6395\n",
            "Epoch 480/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4497 - accuracy: 0.8890 - val_loss: 0.9064 - val_accuracy: 0.6401\n",
            "Epoch 481/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4590 - accuracy: 0.8828 - val_loss: 0.9066 - val_accuracy: 0.6454\n",
            "Epoch 482/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4641 - accuracy: 0.8846 - val_loss: 0.9084 - val_accuracy: 0.6377\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4625 - accuracy: 0.8762 - val_loss: 0.9089 - val_accuracy: 0.6389\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4647 - accuracy: 0.8790 - val_loss: 0.9095 - val_accuracy: 0.6395\n",
            "Epoch 485/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4674 - accuracy: 0.8803 - val_loss: 0.9074 - val_accuracy: 0.6442\n",
            "Epoch 486/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4704 - accuracy: 0.8709 - val_loss: 0.9065 - val_accuracy: 0.6389\n",
            "Epoch 487/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4764 - accuracy: 0.8772 - val_loss: 0.9080 - val_accuracy: 0.6413\n",
            "Epoch 488/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4746 - accuracy: 0.8724 - val_loss: 0.9090 - val_accuracy: 0.6359\n",
            "\n",
            "Epoch 00488: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4758 - accuracy: 0.8696 - val_loss: 0.9074 - val_accuracy: 0.6377\n",
            "Epoch 490/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4794 - accuracy: 0.8764 - val_loss: 0.9070 - val_accuracy: 0.6407\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4937 - accuracy: 0.8645 - val_loss: 0.9088 - val_accuracy: 0.6418\n",
            "Epoch 492/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4878 - accuracy: 0.8733 - val_loss: 0.9096 - val_accuracy: 0.6395\n",
            "Epoch 493/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4905 - accuracy: 0.8673 - val_loss: 0.9084 - val_accuracy: 0.6430\n",
            "Epoch 494/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4850 - accuracy: 0.8730 - val_loss: 0.9099 - val_accuracy: 0.6413\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4971 - accuracy: 0.8685 - val_loss: 0.9106 - val_accuracy: 0.6407\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4920 - accuracy: 0.8792 - val_loss: 0.9120 - val_accuracy: 0.6383\n",
            "Epoch 497/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4938 - accuracy: 0.8714 - val_loss: 0.9136 - val_accuracy: 0.6383\n",
            "Epoch 498/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4975 - accuracy: 0.8709 - val_loss: 0.9126 - val_accuracy: 0.6413\n",
            "Epoch 499/500\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4933 - accuracy: 0.8763 - val_loss: 0.9120 - val_accuracy: 0.6407\n",
            "Epoch 500/500\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.5031 - accuracy: 0.8706 - val_loss: 0.9148 - val_accuracy: 0.6395\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.9484 - accuracy: 0.5999\n",
            "Test accuracy: 59.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "MW-sU-3wDfQf",
        "outputId": "2e5cb147-944d-45f8-bf35-1dae724d9936"
      },
      "source": [
        "# summarize history for loss\r\n",
        "plt.plot(history.history['loss'],'o')\r\n",
        "plt.plot(history.history['val_loss'],'o')\r\n",
        "plt.title('Visual Transformer model loss with data preprocessing')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq25-1U6JERY",
        "outputId": "922525d4-ebc8-49c9-a26a-176df2478b24"
      },
      "source": [
        "def run_experiment(model):\n",
        "    # optimizer = tfa.optimizers.AdamW(\n",
        "    #     learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    # )\n",
        "\n",
        "    optimizer = tfa.optimizers.SGDW(\n",
        "        learning_rate=learning_rate, momentum=0.95, weight_decay=weight_decay\n",
        "        )\n",
        "    \n",
        "    # def scheduler(epoch, lr):\n",
        "    #     if epoch % 10 != 0:\n",
        "    #         return lr\n",
        "    #     else:\n",
        "    #         return lr * .5\n",
        "    # lr_decay = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "    lr_decay = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=15, verbose=1)\n",
        "\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=50)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        # loss = keras.losses.CategoricalCrossentropy()\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            # keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/content/drive/Shareddrives/EE147/vit_checkpoint/vit_checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1000,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[checkpoint_callback, lr_decay, early_stopping],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    # _, accuracy, top_2_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    # print(f\"Test top 2 accuracy: {round(top_2_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "history = run_experiment(create_vit_classifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "27/27 [==============================] - 11s 79ms/step - loss: 2.9108 - accuracy: 0.2579 - val_loss: 1.4206 - val_accuracy: 0.2660\n",
            "Epoch 2/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 2.0439 - accuracy: 0.2648 - val_loss: 1.3718 - val_accuracy: 0.2796\n",
            "Epoch 3/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.6398 - accuracy: 0.2778 - val_loss: 1.3665 - val_accuracy: 0.2914\n",
            "Epoch 4/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.5117 - accuracy: 0.2815 - val_loss: 1.3661 - val_accuracy: 0.3002\n",
            "Epoch 5/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4650 - accuracy: 0.2798 - val_loss: 1.3657 - val_accuracy: 0.2914\n",
            "Epoch 6/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4400 - accuracy: 0.2884 - val_loss: 1.3647 - val_accuracy: 0.2985\n",
            "Epoch 7/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4160 - accuracy: 0.2917 - val_loss: 1.3643 - val_accuracy: 0.2979\n",
            "Epoch 8/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.4126 - accuracy: 0.2948 - val_loss: 1.3634 - val_accuracy: 0.2949\n",
            "Epoch 9/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3936 - accuracy: 0.3106 - val_loss: 1.3627 - val_accuracy: 0.2937\n",
            "Epoch 10/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3942 - accuracy: 0.3014 - val_loss: 1.3615 - val_accuracy: 0.2961\n",
            "Epoch 11/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3920 - accuracy: 0.2898 - val_loss: 1.3600 - val_accuracy: 0.2996\n",
            "Epoch 12/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3738 - accuracy: 0.3024 - val_loss: 1.3593 - val_accuracy: 0.3056\n",
            "Epoch 13/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3654 - accuracy: 0.3221 - val_loss: 1.3577 - val_accuracy: 0.3115\n",
            "Epoch 14/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3711 - accuracy: 0.3124 - val_loss: 1.3556 - val_accuracy: 0.3144\n",
            "Epoch 15/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.3616 - accuracy: 0.3200 - val_loss: 1.3538 - val_accuracy: 0.3197\n",
            "Epoch 16/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3573 - accuracy: 0.3258 - val_loss: 1.3519 - val_accuracy: 0.3186\n",
            "Epoch 17/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3515 - accuracy: 0.3329 - val_loss: 1.3493 - val_accuracy: 0.3221\n",
            "Epoch 18/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3409 - accuracy: 0.3516 - val_loss: 1.3463 - val_accuracy: 0.3262\n",
            "Epoch 19/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3416 - accuracy: 0.3456 - val_loss: 1.3436 - val_accuracy: 0.3268\n",
            "Epoch 20/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 1.3475 - accuracy: 0.3385 - val_loss: 1.3412 - val_accuracy: 0.3322\n",
            "Epoch 21/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 1.3408 - accuracy: 0.3423 - val_loss: 1.3388 - val_accuracy: 0.3345\n",
            "Epoch 22/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3396 - accuracy: 0.3398 - val_loss: 1.3368 - val_accuracy: 0.3363\n",
            "Epoch 23/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3296 - accuracy: 0.3624 - val_loss: 1.3343 - val_accuracy: 0.3398\n",
            "Epoch 24/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3280 - accuracy: 0.3503 - val_loss: 1.3312 - val_accuracy: 0.3428\n",
            "Epoch 25/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3240 - accuracy: 0.3510 - val_loss: 1.3282 - val_accuracy: 0.3463\n",
            "Epoch 26/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3249 - accuracy: 0.3614 - val_loss: 1.3251 - val_accuracy: 0.3534\n",
            "Epoch 27/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3121 - accuracy: 0.3647 - val_loss: 1.3211 - val_accuracy: 0.3517\n",
            "Epoch 28/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 1.3076 - accuracy: 0.3770 - val_loss: 1.3172 - val_accuracy: 0.3517\n",
            "Epoch 29/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3105 - accuracy: 0.3709 - val_loss: 1.3145 - val_accuracy: 0.3558\n",
            "Epoch 30/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2891 - accuracy: 0.3993 - val_loss: 1.3110 - val_accuracy: 0.3546\n",
            "Epoch 31/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.3024 - accuracy: 0.3733 - val_loss: 1.3088 - val_accuracy: 0.3576\n",
            "Epoch 32/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2867 - accuracy: 0.3947 - val_loss: 1.3069 - val_accuracy: 0.3558\n",
            "Epoch 33/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2933 - accuracy: 0.3857 - val_loss: 1.3044 - val_accuracy: 0.3546\n",
            "Epoch 34/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2934 - accuracy: 0.3941 - val_loss: 1.3021 - val_accuracy: 0.3576\n",
            "Epoch 35/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2731 - accuracy: 0.4094 - val_loss: 1.2994 - val_accuracy: 0.3576\n",
            "Epoch 36/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2820 - accuracy: 0.3911 - val_loss: 1.2970 - val_accuracy: 0.3570\n",
            "Epoch 37/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2643 - accuracy: 0.4229 - val_loss: 1.2943 - val_accuracy: 0.3587\n",
            "Epoch 38/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2719 - accuracy: 0.4104 - val_loss: 1.2923 - val_accuracy: 0.3576\n",
            "Epoch 39/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2742 - accuracy: 0.4068 - val_loss: 1.2908 - val_accuracy: 0.3564\n",
            "Epoch 40/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2516 - accuracy: 0.4263 - val_loss: 1.2885 - val_accuracy: 0.3570\n",
            "Epoch 41/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2598 - accuracy: 0.4110 - val_loss: 1.2862 - val_accuracy: 0.3611\n",
            "Epoch 42/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2477 - accuracy: 0.4193 - val_loss: 1.2829 - val_accuracy: 0.3629\n",
            "Epoch 43/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2447 - accuracy: 0.4231 - val_loss: 1.2789 - val_accuracy: 0.3658\n",
            "Epoch 44/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2429 - accuracy: 0.4347 - val_loss: 1.2760 - val_accuracy: 0.3664\n",
            "Epoch 45/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2290 - accuracy: 0.4426 - val_loss: 1.2730 - val_accuracy: 0.3729\n",
            "Epoch 46/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.2256 - accuracy: 0.4300 - val_loss: 1.2702 - val_accuracy: 0.3723\n",
            "Epoch 47/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.2213 - accuracy: 0.4388 - val_loss: 1.2667 - val_accuracy: 0.3765\n",
            "Epoch 48/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2254 - accuracy: 0.4466 - val_loss: 1.2652 - val_accuracy: 0.3783\n",
            "Epoch 49/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2081 - accuracy: 0.4601 - val_loss: 1.2609 - val_accuracy: 0.3848\n",
            "Epoch 50/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.2014 - accuracy: 0.4510 - val_loss: 1.2572 - val_accuracy: 0.3913\n",
            "Epoch 51/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1912 - accuracy: 0.4642 - val_loss: 1.2528 - val_accuracy: 0.3966\n",
            "Epoch 52/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1860 - accuracy: 0.4719 - val_loss: 1.2489 - val_accuracy: 0.3983\n",
            "Epoch 53/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1844 - accuracy: 0.4799 - val_loss: 1.2460 - val_accuracy: 0.3960\n",
            "Epoch 54/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1617 - accuracy: 0.4910 - val_loss: 1.2408 - val_accuracy: 0.4048\n",
            "Epoch 55/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1598 - accuracy: 0.4887 - val_loss: 1.2378 - val_accuracy: 0.4143\n",
            "Epoch 56/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1578 - accuracy: 0.4988 - val_loss: 1.2353 - val_accuracy: 0.4060\n",
            "Epoch 57/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1630 - accuracy: 0.4834 - val_loss: 1.2323 - val_accuracy: 0.4096\n",
            "Epoch 58/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1300 - accuracy: 0.4966 - val_loss: 1.2278 - val_accuracy: 0.4196\n",
            "Epoch 59/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1441 - accuracy: 0.4982 - val_loss: 1.2236 - val_accuracy: 0.4214\n",
            "Epoch 60/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1351 - accuracy: 0.4961 - val_loss: 1.2184 - val_accuracy: 0.4267\n",
            "Epoch 61/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1255 - accuracy: 0.5113 - val_loss: 1.2138 - val_accuracy: 0.4303\n",
            "Epoch 62/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1223 - accuracy: 0.5038 - val_loss: 1.2078 - val_accuracy: 0.4397\n",
            "Epoch 63/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1145 - accuracy: 0.5192 - val_loss: 1.2034 - val_accuracy: 0.4403\n",
            "Epoch 64/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0910 - accuracy: 0.5288 - val_loss: 1.2011 - val_accuracy: 0.4462\n",
            "Epoch 65/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.1016 - accuracy: 0.5211 - val_loss: 1.1981 - val_accuracy: 0.4498\n",
            "Epoch 66/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0778 - accuracy: 0.5400 - val_loss: 1.1943 - val_accuracy: 0.4521\n",
            "Epoch 67/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0827 - accuracy: 0.5271 - val_loss: 1.1896 - val_accuracy: 0.4610\n",
            "Epoch 68/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0713 - accuracy: 0.5376 - val_loss: 1.1857 - val_accuracy: 0.4598\n",
            "Epoch 69/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0631 - accuracy: 0.5486 - val_loss: 1.1819 - val_accuracy: 0.4634\n",
            "Epoch 70/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0338 - accuracy: 0.5556 - val_loss: 1.1780 - val_accuracy: 0.4693\n",
            "Epoch 71/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0184 - accuracy: 0.5663 - val_loss: 1.1758 - val_accuracy: 0.4645\n",
            "Epoch 72/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0255 - accuracy: 0.5577 - val_loss: 1.1713 - val_accuracy: 0.4775\n",
            "Epoch 73/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 1.0095 - accuracy: 0.5622 - val_loss: 1.1677 - val_accuracy: 0.4799\n",
            "Epoch 74/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 1.0176 - accuracy: 0.5652 - val_loss: 1.1622 - val_accuracy: 0.4882\n",
            "Epoch 75/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.9978 - accuracy: 0.5748 - val_loss: 1.1579 - val_accuracy: 0.4882\n",
            "Epoch 76/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.9852 - accuracy: 0.5923 - val_loss: 1.1548 - val_accuracy: 0.4900\n",
            "Epoch 77/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9728 - accuracy: 0.5798 - val_loss: 1.1517 - val_accuracy: 0.4947\n",
            "Epoch 78/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9763 - accuracy: 0.5925 - val_loss: 1.1457 - val_accuracy: 0.5030\n",
            "Epoch 79/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9602 - accuracy: 0.5980 - val_loss: 1.1460 - val_accuracy: 0.5000\n",
            "Epoch 80/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9532 - accuracy: 0.6072 - val_loss: 1.1439 - val_accuracy: 0.4982\n",
            "Epoch 81/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9439 - accuracy: 0.6049 - val_loss: 1.1431 - val_accuracy: 0.5053\n",
            "Epoch 82/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9303 - accuracy: 0.6117 - val_loss: 1.1371 - val_accuracy: 0.5077\n",
            "Epoch 83/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9354 - accuracy: 0.6227 - val_loss: 1.1367 - val_accuracy: 0.5065\n",
            "Epoch 84/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9076 - accuracy: 0.6274 - val_loss: 1.1353 - val_accuracy: 0.5030\n",
            "Epoch 85/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.9252 - accuracy: 0.6154 - val_loss: 1.1337 - val_accuracy: 0.5100\n",
            "Epoch 86/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.9040 - accuracy: 0.6347 - val_loss: 1.1296 - val_accuracy: 0.5124\n",
            "Epoch 87/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.8820 - accuracy: 0.6435 - val_loss: 1.1286 - val_accuracy: 0.5124\n",
            "Epoch 88/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8789 - accuracy: 0.6443 - val_loss: 1.1259 - val_accuracy: 0.5071\n",
            "Epoch 89/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8660 - accuracy: 0.6466 - val_loss: 1.1216 - val_accuracy: 0.5071\n",
            "Epoch 90/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8645 - accuracy: 0.6533 - val_loss: 1.1200 - val_accuracy: 0.5177\n",
            "Epoch 91/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8448 - accuracy: 0.6654 - val_loss: 1.1174 - val_accuracy: 0.5242\n",
            "Epoch 92/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.8407 - accuracy: 0.6611 - val_loss: 1.1156 - val_accuracy: 0.5195\n",
            "Epoch 93/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8249 - accuracy: 0.6699 - val_loss: 1.1179 - val_accuracy: 0.5165\n",
            "Epoch 94/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8333 - accuracy: 0.6656 - val_loss: 1.1121 - val_accuracy: 0.5219\n",
            "Epoch 95/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8184 - accuracy: 0.6703 - val_loss: 1.1127 - val_accuracy: 0.5195\n",
            "Epoch 96/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.8126 - accuracy: 0.6749 - val_loss: 1.1113 - val_accuracy: 0.5201\n",
            "Epoch 97/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7931 - accuracy: 0.6783 - val_loss: 1.1060 - val_accuracy: 0.5248\n",
            "Epoch 98/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7737 - accuracy: 0.6942 - val_loss: 1.1091 - val_accuracy: 0.5225\n",
            "Epoch 99/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7881 - accuracy: 0.6853 - val_loss: 1.1057 - val_accuracy: 0.5254\n",
            "Epoch 100/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 0.7705 - accuracy: 0.6874 - val_loss: 1.0941 - val_accuracy: 0.5325\n",
            "Epoch 101/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7620 - accuracy: 0.7025 - val_loss: 1.0994 - val_accuracy: 0.5337\n",
            "Epoch 102/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7429 - accuracy: 0.7120 - val_loss: 1.0999 - val_accuracy: 0.5319\n",
            "Epoch 103/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.7487 - accuracy: 0.7085 - val_loss: 1.0903 - val_accuracy: 0.5449\n",
            "Epoch 104/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7182 - accuracy: 0.7143 - val_loss: 1.0874 - val_accuracy: 0.5461\n",
            "Epoch 105/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6996 - accuracy: 0.7261 - val_loss: 1.0933 - val_accuracy: 0.5366\n",
            "Epoch 106/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7018 - accuracy: 0.7196 - val_loss: 1.0919 - val_accuracy: 0.5402\n",
            "Epoch 107/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7050 - accuracy: 0.7219 - val_loss: 1.0906 - val_accuracy: 0.5449\n",
            "Epoch 108/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6869 - accuracy: 0.7281 - val_loss: 1.0980 - val_accuracy: 0.5473\n",
            "Epoch 109/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.7020 - accuracy: 0.7326 - val_loss: 1.0906 - val_accuracy: 0.5579\n",
            "Epoch 110/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6819 - accuracy: 0.7402 - val_loss: 1.0953 - val_accuracy: 0.5573\n",
            "Epoch 111/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6748 - accuracy: 0.7399 - val_loss: 1.0954 - val_accuracy: 0.5502\n",
            "Epoch 112/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6481 - accuracy: 0.7504 - val_loss: 1.0966 - val_accuracy: 0.5579\n",
            "Epoch 113/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6664 - accuracy: 0.7393 - val_loss: 1.0820 - val_accuracy: 0.5668\n",
            "Epoch 114/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6480 - accuracy: 0.7531 - val_loss: 1.0929 - val_accuracy: 0.5567\n",
            "Epoch 115/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6416 - accuracy: 0.7563 - val_loss: 1.0898 - val_accuracy: 0.5567\n",
            "Epoch 116/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6033 - accuracy: 0.7803 - val_loss: 1.0831 - val_accuracy: 0.5662\n",
            "Epoch 117/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6241 - accuracy: 0.7560 - val_loss: 1.0886 - val_accuracy: 0.5615\n",
            "Epoch 118/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6081 - accuracy: 0.7687 - val_loss: 1.0872 - val_accuracy: 0.5721\n",
            "Epoch 119/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6114 - accuracy: 0.7693 - val_loss: 1.0859 - val_accuracy: 0.5709\n",
            "Epoch 120/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5769 - accuracy: 0.7857 - val_loss: 1.0909 - val_accuracy: 0.5638\n",
            "Epoch 121/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5655 - accuracy: 0.7901 - val_loss: 1.0947 - val_accuracy: 0.5609\n",
            "Epoch 122/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 0.5717 - accuracy: 0.7808 - val_loss: 1.0977 - val_accuracy: 0.5621\n",
            "Epoch 123/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5806 - accuracy: 0.7828 - val_loss: 1.0946 - val_accuracy: 0.5662\n",
            "Epoch 124/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5668 - accuracy: 0.7796 - val_loss: 1.0944 - val_accuracy: 0.5691\n",
            "Epoch 125/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5611 - accuracy: 0.7922 - val_loss: 1.0765 - val_accuracy: 0.5774\n",
            "Epoch 126/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5462 - accuracy: 0.7962 - val_loss: 1.0893 - val_accuracy: 0.5792\n",
            "Epoch 127/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5404 - accuracy: 0.7971 - val_loss: 1.0862 - val_accuracy: 0.5739\n",
            "Epoch 128/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5252 - accuracy: 0.8096 - val_loss: 1.0896 - val_accuracy: 0.5668\n",
            "Epoch 129/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5368 - accuracy: 0.8037 - val_loss: 1.0823 - val_accuracy: 0.5733\n",
            "Epoch 130/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5163 - accuracy: 0.8072 - val_loss: 1.0856 - val_accuracy: 0.5833\n",
            "Epoch 131/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.5033 - accuracy: 0.8228 - val_loss: 1.0878 - val_accuracy: 0.5792\n",
            "Epoch 132/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4999 - accuracy: 0.8126 - val_loss: 1.0923 - val_accuracy: 0.5833\n",
            "Epoch 133/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4901 - accuracy: 0.8203 - val_loss: 1.0884 - val_accuracy: 0.5780\n",
            "Epoch 134/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4797 - accuracy: 0.8237 - val_loss: 1.0859 - val_accuracy: 0.5757\n",
            "Epoch 135/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4866 - accuracy: 0.8177 - val_loss: 1.0905 - val_accuracy: 0.5881\n",
            "Epoch 136/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4893 - accuracy: 0.8164 - val_loss: 1.0875 - val_accuracy: 0.5857\n",
            "Epoch 137/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4681 - accuracy: 0.8229 - val_loss: 1.0844 - val_accuracy: 0.5845\n",
            "Epoch 138/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4713 - accuracy: 0.8255 - val_loss: 1.0849 - val_accuracy: 0.5916\n",
            "Epoch 139/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4620 - accuracy: 0.8319 - val_loss: 1.0970 - val_accuracy: 0.5952\n",
            "Epoch 140/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4544 - accuracy: 0.8269 - val_loss: 1.0843 - val_accuracy: 0.5887\n",
            "\n",
            "Epoch 00140: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 141/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4517 - accuracy: 0.8321 - val_loss: 1.1030 - val_accuracy: 0.5922\n",
            "Epoch 142/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4258 - accuracy: 0.8413 - val_loss: 1.0951 - val_accuracy: 0.6017\n",
            "Epoch 143/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4376 - accuracy: 0.8371 - val_loss: 1.1024 - val_accuracy: 0.5898\n",
            "Epoch 144/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4295 - accuracy: 0.8471 - val_loss: 1.0926 - val_accuracy: 0.5934\n",
            "Epoch 145/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4282 - accuracy: 0.8474 - val_loss: 1.0877 - val_accuracy: 0.5916\n",
            "Epoch 146/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4326 - accuracy: 0.8435 - val_loss: 1.0898 - val_accuracy: 0.5999\n",
            "Epoch 147/1000\n",
            "27/27 [==============================] - 1s 38ms/step - loss: 0.4185 - accuracy: 0.8532 - val_loss: 1.0885 - val_accuracy: 0.5975\n",
            "Epoch 148/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4107 - accuracy: 0.8570 - val_loss: 1.0884 - val_accuracy: 0.5981\n",
            "Epoch 149/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4168 - accuracy: 0.8519 - val_loss: 1.0866 - val_accuracy: 0.5940\n",
            "Epoch 150/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3942 - accuracy: 0.8658 - val_loss: 1.0863 - val_accuracy: 0.5946\n",
            "Epoch 151/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4066 - accuracy: 0.8535 - val_loss: 1.0835 - val_accuracy: 0.5928\n",
            "Epoch 152/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4124 - accuracy: 0.8582 - val_loss: 1.0853 - val_accuracy: 0.5975\n",
            "Epoch 153/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3994 - accuracy: 0.8636 - val_loss: 1.0844 - val_accuracy: 0.5969\n",
            "Epoch 154/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3998 - accuracy: 0.8554 - val_loss: 1.0825 - val_accuracy: 0.5957\n",
            "Epoch 155/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3897 - accuracy: 0.8590 - val_loss: 1.0870 - val_accuracy: 0.5963\n",
            "\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 156/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3798 - accuracy: 0.8693 - val_loss: 1.0916 - val_accuracy: 0.5952\n",
            "Epoch 157/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3899 - accuracy: 0.8646 - val_loss: 1.0761 - val_accuracy: 0.6005\n",
            "Epoch 158/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3801 - accuracy: 0.8693 - val_loss: 1.0747 - val_accuracy: 0.6005\n",
            "Epoch 159/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3947 - accuracy: 0.8638 - val_loss: 1.0722 - val_accuracy: 0.6076\n",
            "Epoch 160/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3770 - accuracy: 0.8712 - val_loss: 1.0756 - val_accuracy: 0.6034\n",
            "Epoch 161/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3931 - accuracy: 0.8635 - val_loss: 1.0745 - val_accuracy: 0.6017\n",
            "Epoch 162/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3996 - accuracy: 0.8609 - val_loss: 1.0721 - val_accuracy: 0.6028\n",
            "Epoch 163/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3995 - accuracy: 0.8625 - val_loss: 1.0702 - val_accuracy: 0.6011\n",
            "Epoch 164/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3963 - accuracy: 0.8595 - val_loss: 1.0726 - val_accuracy: 0.5975\n",
            "Epoch 165/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3872 - accuracy: 0.8706 - val_loss: 1.0706 - val_accuracy: 0.5993\n",
            "Epoch 166/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3969 - accuracy: 0.8698 - val_loss: 1.0622 - val_accuracy: 0.6005\n",
            "Epoch 167/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3891 - accuracy: 0.8678 - val_loss: 1.0667 - val_accuracy: 0.5922\n",
            "Epoch 168/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3811 - accuracy: 0.8699 - val_loss: 1.0630 - val_accuracy: 0.5981\n",
            "Epoch 169/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3772 - accuracy: 0.8691 - val_loss: 1.0581 - val_accuracy: 0.5963\n",
            "Epoch 170/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4014 - accuracy: 0.8639 - val_loss: 1.0617 - val_accuracy: 0.6011\n",
            "Epoch 171/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3949 - accuracy: 0.8688 - val_loss: 1.0664 - val_accuracy: 0.5981\n",
            "Epoch 172/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3871 - accuracy: 0.8670 - val_loss: 1.0536 - val_accuracy: 0.6064\n",
            "Epoch 173/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3908 - accuracy: 0.8663 - val_loss: 1.0557 - val_accuracy: 0.6052\n",
            "Epoch 174/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3798 - accuracy: 0.8761 - val_loss: 1.0569 - val_accuracy: 0.5975\n",
            "Epoch 175/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3917 - accuracy: 0.8650 - val_loss: 1.0594 - val_accuracy: 0.6022\n",
            "Epoch 176/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3786 - accuracy: 0.8711 - val_loss: 1.0549 - val_accuracy: 0.6005\n",
            "Epoch 177/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3730 - accuracy: 0.8735 - val_loss: 1.0553 - val_accuracy: 0.6017\n",
            "Epoch 178/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3823 - accuracy: 0.8747 - val_loss: 1.0485 - val_accuracy: 0.6064\n",
            "Epoch 179/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3828 - accuracy: 0.8685 - val_loss: 1.0498 - val_accuracy: 0.6017\n",
            "Epoch 180/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3782 - accuracy: 0.8682 - val_loss: 1.0501 - val_accuracy: 0.6034\n",
            "Epoch 181/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3678 - accuracy: 0.8772 - val_loss: 1.0564 - val_accuracy: 0.5975\n",
            "Epoch 182/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3652 - accuracy: 0.8755 - val_loss: 1.0489 - val_accuracy: 0.5952\n",
            "Epoch 183/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3868 - accuracy: 0.8689 - val_loss: 1.0429 - val_accuracy: 0.5999\n",
            "Epoch 184/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3763 - accuracy: 0.8717 - val_loss: 1.0424 - val_accuracy: 0.5969\n",
            "Epoch 185/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3921 - accuracy: 0.8692 - val_loss: 1.0451 - val_accuracy: 0.5975\n",
            "Epoch 186/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3806 - accuracy: 0.8734 - val_loss: 1.0483 - val_accuracy: 0.6064\n",
            "Epoch 187/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3954 - accuracy: 0.8675 - val_loss: 1.0400 - val_accuracy: 0.6058\n",
            "Epoch 188/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3705 - accuracy: 0.8764 - val_loss: 1.0401 - val_accuracy: 0.6022\n",
            "Epoch 189/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3839 - accuracy: 0.8713 - val_loss: 1.0448 - val_accuracy: 0.5987\n",
            "Epoch 190/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3786 - accuracy: 0.8729 - val_loss: 1.0406 - val_accuracy: 0.6005\n",
            "Epoch 191/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3715 - accuracy: 0.8802 - val_loss: 1.0381 - val_accuracy: 0.6052\n",
            "Epoch 192/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3781 - accuracy: 0.8753 - val_loss: 1.0444 - val_accuracy: 0.6034\n",
            "Epoch 193/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3741 - accuracy: 0.8728 - val_loss: 1.0374 - val_accuracy: 0.6046\n",
            "Epoch 194/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3749 - accuracy: 0.8753 - val_loss: 1.0428 - val_accuracy: 0.6005\n",
            "Epoch 195/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.3817 - accuracy: 0.8756 - val_loss: 1.0422 - val_accuracy: 0.6022\n",
            "Epoch 196/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3810 - accuracy: 0.8730 - val_loss: 1.0358 - val_accuracy: 0.6046\n",
            "Epoch 197/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3792 - accuracy: 0.8727 - val_loss: 1.0354 - val_accuracy: 0.6082\n",
            "Epoch 198/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3868 - accuracy: 0.8704 - val_loss: 1.0440 - val_accuracy: 0.6005\n",
            "Epoch 199/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3725 - accuracy: 0.8761 - val_loss: 1.0399 - val_accuracy: 0.6040\n",
            "Epoch 200/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3681 - accuracy: 0.8833 - val_loss: 1.0462 - val_accuracy: 0.6064\n",
            "Epoch 201/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3574 - accuracy: 0.8874 - val_loss: 1.0376 - val_accuracy: 0.6017\n",
            "Epoch 202/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3781 - accuracy: 0.8701 - val_loss: 1.0428 - val_accuracy: 0.5999\n",
            "Epoch 203/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3826 - accuracy: 0.8694 - val_loss: 1.0333 - val_accuracy: 0.5963\n",
            "Epoch 204/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3846 - accuracy: 0.8734 - val_loss: 1.0364 - val_accuracy: 0.5957\n",
            "Epoch 205/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3665 - accuracy: 0.8823 - val_loss: 1.0366 - val_accuracy: 0.5999\n",
            "Epoch 206/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3711 - accuracy: 0.8764 - val_loss: 1.0392 - val_accuracy: 0.5969\n",
            "Epoch 207/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3628 - accuracy: 0.8835 - val_loss: 1.0302 - val_accuracy: 0.6011\n",
            "Epoch 208/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3660 - accuracy: 0.8786 - val_loss: 1.0339 - val_accuracy: 0.6034\n",
            "Epoch 209/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3665 - accuracy: 0.8846 - val_loss: 1.0344 - val_accuracy: 0.6040\n",
            "Epoch 210/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3609 - accuracy: 0.8838 - val_loss: 1.0397 - val_accuracy: 0.5975\n",
            "Epoch 211/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3660 - accuracy: 0.8853 - val_loss: 1.0277 - val_accuracy: 0.6087\n",
            "Epoch 212/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3804 - accuracy: 0.8744 - val_loss: 1.0250 - val_accuracy: 0.6076\n",
            "Epoch 213/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3707 - accuracy: 0.8820 - val_loss: 1.0359 - val_accuracy: 0.5946\n",
            "Epoch 214/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3778 - accuracy: 0.8760 - val_loss: 1.0245 - val_accuracy: 0.6070\n",
            "Epoch 215/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3718 - accuracy: 0.8828 - val_loss: 1.0332 - val_accuracy: 0.6040\n",
            "Epoch 216/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3718 - accuracy: 0.8776 - val_loss: 1.0296 - val_accuracy: 0.6040\n",
            "Epoch 217/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3645 - accuracy: 0.8825 - val_loss: 1.0210 - val_accuracy: 0.6046\n",
            "Epoch 218/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3579 - accuracy: 0.8843 - val_loss: 1.0284 - val_accuracy: 0.6046\n",
            "Epoch 219/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3797 - accuracy: 0.8738 - val_loss: 1.0186 - val_accuracy: 0.6046\n",
            "Epoch 220/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3458 - accuracy: 0.8930 - val_loss: 1.0261 - val_accuracy: 0.6017\n",
            "Epoch 221/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3577 - accuracy: 0.8820 - val_loss: 1.0242 - val_accuracy: 0.6052\n",
            "Epoch 222/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3606 - accuracy: 0.8804 - val_loss: 1.0241 - val_accuracy: 0.6093\n",
            "Epoch 223/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3589 - accuracy: 0.8843 - val_loss: 1.0182 - val_accuracy: 0.6064\n",
            "Epoch 224/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3561 - accuracy: 0.8838 - val_loss: 1.0261 - val_accuracy: 0.6022\n",
            "Epoch 225/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3699 - accuracy: 0.8819 - val_loss: 1.0239 - val_accuracy: 0.6011\n",
            "Epoch 226/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3555 - accuracy: 0.8835 - val_loss: 1.0269 - val_accuracy: 0.6058\n",
            "Epoch 227/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3665 - accuracy: 0.8780 - val_loss: 1.0210 - val_accuracy: 0.6087\n",
            "Epoch 228/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3460 - accuracy: 0.8893 - val_loss: 1.0187 - val_accuracy: 0.6034\n",
            "Epoch 229/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3559 - accuracy: 0.8847 - val_loss: 1.0200 - val_accuracy: 0.5987\n",
            "Epoch 230/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3422 - accuracy: 0.8926 - val_loss: 1.0301 - val_accuracy: 0.6058\n",
            "Epoch 231/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3520 - accuracy: 0.8878 - val_loss: 1.0243 - val_accuracy: 0.6093\n",
            "Epoch 232/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3648 - accuracy: 0.8833 - val_loss: 1.0141 - val_accuracy: 0.6147\n",
            "Epoch 233/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3630 - accuracy: 0.8826 - val_loss: 1.0237 - val_accuracy: 0.6028\n",
            "Epoch 234/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3568 - accuracy: 0.8883 - val_loss: 1.0197 - val_accuracy: 0.6111\n",
            "Epoch 235/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3586 - accuracy: 0.8842 - val_loss: 1.0145 - val_accuracy: 0.6058\n",
            "Epoch 236/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3500 - accuracy: 0.8873 - val_loss: 1.0165 - val_accuracy: 0.6117\n",
            "Epoch 237/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3530 - accuracy: 0.8937 - val_loss: 1.0248 - val_accuracy: 0.6093\n",
            "Epoch 238/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3585 - accuracy: 0.8771 - val_loss: 1.0193 - val_accuracy: 0.6046\n",
            "Epoch 239/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3447 - accuracy: 0.8856 - val_loss: 1.0092 - val_accuracy: 0.6135\n",
            "Epoch 240/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3447 - accuracy: 0.8863 - val_loss: 1.0055 - val_accuracy: 0.6087\n",
            "Epoch 241/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3588 - accuracy: 0.8866 - val_loss: 1.0051 - val_accuracy: 0.6058\n",
            "Epoch 242/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3411 - accuracy: 0.8947 - val_loss: 1.0160 - val_accuracy: 0.6082\n",
            "Epoch 243/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3415 - accuracy: 0.8932 - val_loss: 1.0136 - val_accuracy: 0.6070\n",
            "Epoch 244/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3575 - accuracy: 0.8767 - val_loss: 1.0142 - val_accuracy: 0.6076\n",
            "Epoch 245/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3383 - accuracy: 0.8945 - val_loss: 1.0020 - val_accuracy: 0.6099\n",
            "Epoch 246/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3566 - accuracy: 0.8867 - val_loss: 1.0140 - val_accuracy: 0.6082\n",
            "Epoch 247/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3413 - accuracy: 0.8938 - val_loss: 1.0124 - val_accuracy: 0.6087\n",
            "Epoch 248/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3407 - accuracy: 0.8918 - val_loss: 1.0141 - val_accuracy: 0.6070\n",
            "Epoch 249/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3419 - accuracy: 0.8917 - val_loss: 1.0066 - val_accuracy: 0.6040\n",
            "Epoch 250/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3461 - accuracy: 0.8837 - val_loss: 1.0051 - val_accuracy: 0.6129\n",
            "Epoch 251/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3341 - accuracy: 0.8934 - val_loss: 1.0002 - val_accuracy: 0.6164\n",
            "Epoch 252/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3495 - accuracy: 0.8871 - val_loss: 1.0133 - val_accuracy: 0.6093\n",
            "Epoch 253/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3360 - accuracy: 0.8902 - val_loss: 1.0002 - val_accuracy: 0.6093\n",
            "Epoch 254/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3417 - accuracy: 0.8913 - val_loss: 1.0081 - val_accuracy: 0.6082\n",
            "Epoch 255/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3428 - accuracy: 0.8899 - val_loss: 1.0070 - val_accuracy: 0.6093\n",
            "Epoch 256/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3481 - accuracy: 0.8871 - val_loss: 1.0087 - val_accuracy: 0.6141\n",
            "Epoch 257/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3481 - accuracy: 0.8960 - val_loss: 1.0006 - val_accuracy: 0.6076\n",
            "Epoch 258/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3310 - accuracy: 0.8976 - val_loss: 1.0015 - val_accuracy: 0.6105\n",
            "Epoch 259/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3492 - accuracy: 0.8790 - val_loss: 1.0008 - val_accuracy: 0.6052\n",
            "Epoch 260/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3456 - accuracy: 0.8904 - val_loss: 1.0104 - val_accuracy: 0.6034\n",
            "Epoch 261/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3325 - accuracy: 0.8905 - val_loss: 0.9977 - val_accuracy: 0.6158\n",
            "Epoch 262/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3231 - accuracy: 0.8948 - val_loss: 1.0074 - val_accuracy: 0.6129\n",
            "Epoch 263/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3472 - accuracy: 0.8847 - val_loss: 1.0027 - val_accuracy: 0.6099\n",
            "Epoch 264/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3454 - accuracy: 0.8946 - val_loss: 1.0003 - val_accuracy: 0.6164\n",
            "Epoch 265/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3387 - accuracy: 0.8931 - val_loss: 1.0083 - val_accuracy: 0.6123\n",
            "Epoch 266/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3342 - accuracy: 0.8945 - val_loss: 1.0025 - val_accuracy: 0.6093\n",
            "Epoch 267/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3423 - accuracy: 0.8926 - val_loss: 1.0116 - val_accuracy: 0.6070\n",
            "Epoch 268/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3404 - accuracy: 0.8940 - val_loss: 0.9995 - val_accuracy: 0.6099\n",
            "Epoch 269/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3417 - accuracy: 0.8906 - val_loss: 1.0067 - val_accuracy: 0.6034\n",
            "Epoch 270/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3468 - accuracy: 0.8895 - val_loss: 0.9938 - val_accuracy: 0.6123\n",
            "Epoch 271/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3219 - accuracy: 0.9004 - val_loss: 1.0053 - val_accuracy: 0.6093\n",
            "Epoch 272/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3450 - accuracy: 0.8897 - val_loss: 1.0038 - val_accuracy: 0.6076\n",
            "Epoch 273/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3324 - accuracy: 0.8970 - val_loss: 1.0029 - val_accuracy: 0.6058\n",
            "Epoch 274/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3428 - accuracy: 0.8914 - val_loss: 0.9995 - val_accuracy: 0.6087\n",
            "Epoch 275/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3237 - accuracy: 0.8979 - val_loss: 1.0065 - val_accuracy: 0.6028\n",
            "Epoch 276/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3515 - accuracy: 0.8948 - val_loss: 1.0034 - val_accuracy: 0.6058\n",
            "Epoch 277/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3485 - accuracy: 0.8865 - val_loss: 0.9951 - val_accuracy: 0.6099\n",
            "Epoch 278/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3361 - accuracy: 0.9013 - val_loss: 0.9980 - val_accuracy: 0.6129\n",
            "Epoch 279/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3204 - accuracy: 0.9035 - val_loss: 0.9941 - val_accuracy: 0.6064\n",
            "Epoch 280/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3429 - accuracy: 0.8870 - val_loss: 1.0008 - val_accuracy: 0.6093\n",
            "Epoch 281/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3504 - accuracy: 0.8849 - val_loss: 0.9960 - val_accuracy: 0.6082\n",
            "Epoch 282/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3216 - accuracy: 0.9003 - val_loss: 0.9985 - val_accuracy: 0.6087\n",
            "Epoch 283/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3412 - accuracy: 0.8861 - val_loss: 0.9811 - val_accuracy: 0.6188\n",
            "Epoch 284/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3334 - accuracy: 0.8953 - val_loss: 0.9917 - val_accuracy: 0.6111\n",
            "Epoch 285/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3294 - accuracy: 0.8943 - val_loss: 0.9956 - val_accuracy: 0.6147\n",
            "Epoch 286/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3334 - accuracy: 0.8986 - val_loss: 0.9907 - val_accuracy: 0.6129\n",
            "Epoch 287/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3380 - accuracy: 0.8923 - val_loss: 0.9915 - val_accuracy: 0.6093\n",
            "Epoch 288/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3330 - accuracy: 0.8976 - val_loss: 0.9912 - val_accuracy: 0.6111\n",
            "Epoch 289/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3405 - accuracy: 0.8978 - val_loss: 1.0022 - val_accuracy: 0.6099\n",
            "Epoch 290/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3532 - accuracy: 0.8885 - val_loss: 0.9936 - val_accuracy: 0.6117\n",
            "Epoch 291/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3283 - accuracy: 0.8979 - val_loss: 0.9873 - val_accuracy: 0.6129\n",
            "Epoch 292/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3386 - accuracy: 0.8930 - val_loss: 0.9932 - val_accuracy: 0.6111\n",
            "Epoch 293/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3424 - accuracy: 0.8907 - val_loss: 1.0039 - val_accuracy: 0.6087\n",
            "Epoch 294/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3454 - accuracy: 0.8896 - val_loss: 0.9907 - val_accuracy: 0.6147\n",
            "Epoch 295/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3198 - accuracy: 0.9016 - val_loss: 0.9926 - val_accuracy: 0.6099\n",
            "Epoch 296/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3368 - accuracy: 0.8887 - val_loss: 0.9957 - val_accuracy: 0.6070\n",
            "Epoch 297/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3370 - accuracy: 0.8934 - val_loss: 0.9856 - val_accuracy: 0.6147\n",
            "Epoch 298/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3348 - accuracy: 0.8924 - val_loss: 0.9912 - val_accuracy: 0.6123\n",
            "\n",
            "Epoch 00298: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 299/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3192 - accuracy: 0.8992 - val_loss: 0.9944 - val_accuracy: 0.6123\n",
            "Epoch 300/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3327 - accuracy: 0.8952 - val_loss: 0.9933 - val_accuracy: 0.6135\n",
            "Epoch 301/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3159 - accuracy: 0.9088 - val_loss: 0.9871 - val_accuracy: 0.6123\n",
            "Epoch 302/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3325 - accuracy: 0.8956 - val_loss: 0.9853 - val_accuracy: 0.6152\n",
            "Epoch 303/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3295 - accuracy: 0.9002 - val_loss: 0.9830 - val_accuracy: 0.6111\n",
            "Epoch 304/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3265 - accuracy: 0.9038 - val_loss: 0.9861 - val_accuracy: 0.6164\n",
            "Epoch 305/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3295 - accuracy: 0.8964 - val_loss: 0.9818 - val_accuracy: 0.6152\n",
            "Epoch 306/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3412 - accuracy: 0.8949 - val_loss: 0.9786 - val_accuracy: 0.6147\n",
            "Epoch 307/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3486 - accuracy: 0.8918 - val_loss: 0.9737 - val_accuracy: 0.6188\n",
            "Epoch 308/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3312 - accuracy: 0.8996 - val_loss: 0.9821 - val_accuracy: 0.6170\n",
            "Epoch 309/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3381 - accuracy: 0.8974 - val_loss: 0.9720 - val_accuracy: 0.6158\n",
            "Epoch 310/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3343 - accuracy: 0.8936 - val_loss: 0.9747 - val_accuracy: 0.6182\n",
            "Epoch 311/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3401 - accuracy: 0.8968 - val_loss: 0.9717 - val_accuracy: 0.6206\n",
            "Epoch 312/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3486 - accuracy: 0.8913 - val_loss: 0.9779 - val_accuracy: 0.6182\n",
            "Epoch 313/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3410 - accuracy: 0.8997 - val_loss: 0.9730 - val_accuracy: 0.6194\n",
            "Epoch 314/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3454 - accuracy: 0.8960 - val_loss: 0.9667 - val_accuracy: 0.6176\n",
            "Epoch 315/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3575 - accuracy: 0.8898 - val_loss: 0.9720 - val_accuracy: 0.6123\n",
            "Epoch 316/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3490 - accuracy: 0.8927 - val_loss: 0.9645 - val_accuracy: 0.6152\n",
            "Epoch 317/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3452 - accuracy: 0.8973 - val_loss: 0.9763 - val_accuracy: 0.6087\n",
            "Epoch 318/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3535 - accuracy: 0.8877 - val_loss: 0.9694 - val_accuracy: 0.6147\n",
            "Epoch 319/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3502 - accuracy: 0.8953 - val_loss: 0.9702 - val_accuracy: 0.6164\n",
            "Epoch 320/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3431 - accuracy: 0.9056 - val_loss: 0.9680 - val_accuracy: 0.6176\n",
            "Epoch 321/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3507 - accuracy: 0.8966 - val_loss: 0.9677 - val_accuracy: 0.6200\n",
            "Epoch 322/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3485 - accuracy: 0.9017 - val_loss: 0.9600 - val_accuracy: 0.6164\n",
            "Epoch 323/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3303 - accuracy: 0.9058 - val_loss: 0.9687 - val_accuracy: 0.6176\n",
            "Epoch 324/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3438 - accuracy: 0.8993 - val_loss: 0.9661 - val_accuracy: 0.6223\n",
            "Epoch 325/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3496 - accuracy: 0.8944 - val_loss: 0.9637 - val_accuracy: 0.6194\n",
            "Epoch 326/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3516 - accuracy: 0.8962 - val_loss: 0.9663 - val_accuracy: 0.6135\n",
            "Epoch 327/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3629 - accuracy: 0.8918 - val_loss: 0.9630 - val_accuracy: 0.6129\n",
            "Epoch 328/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3501 - accuracy: 0.8983 - val_loss: 0.9646 - val_accuracy: 0.6158\n",
            "Epoch 329/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3481 - accuracy: 0.8998 - val_loss: 0.9587 - val_accuracy: 0.6188\n",
            "Epoch 330/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3525 - accuracy: 0.8950 - val_loss: 0.9599 - val_accuracy: 0.6200\n",
            "Epoch 331/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3626 - accuracy: 0.8915 - val_loss: 0.9611 - val_accuracy: 0.6176\n",
            "Epoch 332/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3602 - accuracy: 0.8971 - val_loss: 0.9605 - val_accuracy: 0.6176\n",
            "Epoch 333/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3542 - accuracy: 0.8917 - val_loss: 0.9552 - val_accuracy: 0.6212\n",
            "Epoch 334/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3668 - accuracy: 0.8916 - val_loss: 0.9528 - val_accuracy: 0.6235\n",
            "Epoch 335/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3578 - accuracy: 0.8937 - val_loss: 0.9551 - val_accuracy: 0.6152\n",
            "Epoch 336/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3563 - accuracy: 0.8986 - val_loss: 0.9572 - val_accuracy: 0.6217\n",
            "Epoch 337/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3480 - accuracy: 0.9050 - val_loss: 0.9557 - val_accuracy: 0.6194\n",
            "Epoch 338/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3574 - accuracy: 0.8955 - val_loss: 0.9537 - val_accuracy: 0.6217\n",
            "Epoch 339/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3679 - accuracy: 0.8896 - val_loss: 0.9493 - val_accuracy: 0.6176\n",
            "Epoch 340/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3598 - accuracy: 0.8921 - val_loss: 0.9519 - val_accuracy: 0.6188\n",
            "Epoch 341/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3578 - accuracy: 0.8978 - val_loss: 0.9512 - val_accuracy: 0.6235\n",
            "Epoch 342/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3712 - accuracy: 0.8853 - val_loss: 0.9503 - val_accuracy: 0.6176\n",
            "Epoch 343/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3850 - accuracy: 0.8780 - val_loss: 0.9549 - val_accuracy: 0.6194\n",
            "Epoch 344/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3671 - accuracy: 0.8964 - val_loss: 0.9515 - val_accuracy: 0.6212\n",
            "Epoch 345/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.3620 - accuracy: 0.8916 - val_loss: 0.9487 - val_accuracy: 0.6247\n",
            "Epoch 346/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3635 - accuracy: 0.8948 - val_loss: 0.9508 - val_accuracy: 0.6223\n",
            "Epoch 347/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3690 - accuracy: 0.8920 - val_loss: 0.9468 - val_accuracy: 0.6212\n",
            "Epoch 348/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3733 - accuracy: 0.8905 - val_loss: 0.9479 - val_accuracy: 0.6206\n",
            "Epoch 349/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.3783 - accuracy: 0.8844 - val_loss: 0.9464 - val_accuracy: 0.6212\n",
            "Epoch 350/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3686 - accuracy: 0.8889 - val_loss: 0.9492 - val_accuracy: 0.6241\n",
            "Epoch 351/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3651 - accuracy: 0.8914 - val_loss: 0.9493 - val_accuracy: 0.6164\n",
            "Epoch 352/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3741 - accuracy: 0.8915 - val_loss: 0.9429 - val_accuracy: 0.6235\n",
            "Epoch 353/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3822 - accuracy: 0.8848 - val_loss: 0.9467 - val_accuracy: 0.6253\n",
            "Epoch 354/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3677 - accuracy: 0.8971 - val_loss: 0.9508 - val_accuracy: 0.6170\n",
            "Epoch 355/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3932 - accuracy: 0.8900 - val_loss: 0.9478 - val_accuracy: 0.6217\n",
            "Epoch 356/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3769 - accuracy: 0.8886 - val_loss: 0.9416 - val_accuracy: 0.6217\n",
            "Epoch 357/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3861 - accuracy: 0.8859 - val_loss: 0.9520 - val_accuracy: 0.6241\n",
            "Epoch 358/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3808 - accuracy: 0.8939 - val_loss: 0.9507 - val_accuracy: 0.6182\n",
            "Epoch 359/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3791 - accuracy: 0.8950 - val_loss: 0.9477 - val_accuracy: 0.6147\n",
            "Epoch 360/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3888 - accuracy: 0.8787 - val_loss: 0.9432 - val_accuracy: 0.6182\n",
            "Epoch 361/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3886 - accuracy: 0.8868 - val_loss: 0.9458 - val_accuracy: 0.6229\n",
            "Epoch 362/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3822 - accuracy: 0.8857 - val_loss: 0.9425 - val_accuracy: 0.6212\n",
            "Epoch 363/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3909 - accuracy: 0.8822 - val_loss: 0.9436 - val_accuracy: 0.6212\n",
            "Epoch 364/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3906 - accuracy: 0.8864 - val_loss: 0.9403 - val_accuracy: 0.6229\n",
            "Epoch 365/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3815 - accuracy: 0.8953 - val_loss: 0.9448 - val_accuracy: 0.6206\n",
            "Epoch 366/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3887 - accuracy: 0.8811 - val_loss: 0.9468 - val_accuracy: 0.6176\n",
            "Epoch 367/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3931 - accuracy: 0.8866 - val_loss: 0.9449 - val_accuracy: 0.6182\n",
            "Epoch 368/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3896 - accuracy: 0.8909 - val_loss: 0.9457 - val_accuracy: 0.6182\n",
            "Epoch 369/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3821 - accuracy: 0.8887 - val_loss: 0.9416 - val_accuracy: 0.6176\n",
            "Epoch 370/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3983 - accuracy: 0.8805 - val_loss: 0.9423 - val_accuracy: 0.6170\n",
            "Epoch 371/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3828 - accuracy: 0.8928 - val_loss: 0.9461 - val_accuracy: 0.6158\n",
            "Epoch 372/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3902 - accuracy: 0.8867 - val_loss: 0.9452 - val_accuracy: 0.6170\n",
            "Epoch 373/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3910 - accuracy: 0.8837 - val_loss: 0.9378 - val_accuracy: 0.6194\n",
            "Epoch 374/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3927 - accuracy: 0.8823 - val_loss: 0.9419 - val_accuracy: 0.6212\n",
            "Epoch 375/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3925 - accuracy: 0.8849 - val_loss: 0.9387 - val_accuracy: 0.6188\n",
            "Epoch 376/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3936 - accuracy: 0.8862 - val_loss: 0.9409 - val_accuracy: 0.6158\n",
            "Epoch 377/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3977 - accuracy: 0.8848 - val_loss: 0.9362 - val_accuracy: 0.6241\n",
            "Epoch 378/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3990 - accuracy: 0.8810 - val_loss: 0.9426 - val_accuracy: 0.6188\n",
            "Epoch 379/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3981 - accuracy: 0.8852 - val_loss: 0.9407 - val_accuracy: 0.6194\n",
            "Epoch 380/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4035 - accuracy: 0.8790 - val_loss: 0.9362 - val_accuracy: 0.6223\n",
            "Epoch 381/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4036 - accuracy: 0.8853 - val_loss: 0.9431 - val_accuracy: 0.6182\n",
            "Epoch 382/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3940 - accuracy: 0.8906 - val_loss: 0.9372 - val_accuracy: 0.6206\n",
            "Epoch 383/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4010 - accuracy: 0.8818 - val_loss: 0.9312 - val_accuracy: 0.6241\n",
            "Epoch 384/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3869 - accuracy: 0.8933 - val_loss: 0.9376 - val_accuracy: 0.6212\n",
            "Epoch 385/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3942 - accuracy: 0.8878 - val_loss: 0.9328 - val_accuracy: 0.6235\n",
            "Epoch 386/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3945 - accuracy: 0.8835 - val_loss: 0.9370 - val_accuracy: 0.6229\n",
            "Epoch 387/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4008 - accuracy: 0.8800 - val_loss: 0.9331 - val_accuracy: 0.6229\n",
            "Epoch 388/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3964 - accuracy: 0.8871 - val_loss: 0.9388 - val_accuracy: 0.6170\n",
            "Epoch 389/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3965 - accuracy: 0.8891 - val_loss: 0.9378 - val_accuracy: 0.6188\n",
            "Epoch 390/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4028 - accuracy: 0.8808 - val_loss: 0.9355 - val_accuracy: 0.6200\n",
            "Epoch 391/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.3953 - accuracy: 0.8865 - val_loss: 0.9309 - val_accuracy: 0.6277\n",
            "Epoch 392/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4102 - accuracy: 0.8725 - val_loss: 0.9352 - val_accuracy: 0.6176\n",
            "Epoch 393/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3983 - accuracy: 0.8845 - val_loss: 0.9344 - val_accuracy: 0.6265\n",
            "Epoch 394/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4048 - accuracy: 0.8843 - val_loss: 0.9361 - val_accuracy: 0.6217\n",
            "Epoch 395/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4043 - accuracy: 0.8854 - val_loss: 0.9351 - val_accuracy: 0.6283\n",
            "Epoch 396/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3914 - accuracy: 0.8817 - val_loss: 0.9416 - val_accuracy: 0.6229\n",
            "Epoch 397/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3919 - accuracy: 0.8826 - val_loss: 0.9340 - val_accuracy: 0.6212\n",
            "Epoch 398/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4002 - accuracy: 0.8793 - val_loss: 0.9357 - val_accuracy: 0.6206\n",
            "Epoch 399/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4078 - accuracy: 0.8822 - val_loss: 0.9327 - val_accuracy: 0.6182\n",
            "Epoch 400/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.3965 - accuracy: 0.8881 - val_loss: 0.9329 - val_accuracy: 0.6206\n",
            "Epoch 401/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4041 - accuracy: 0.8852 - val_loss: 0.9310 - val_accuracy: 0.6164\n",
            "Epoch 402/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4022 - accuracy: 0.8837 - val_loss: 0.9306 - val_accuracy: 0.6241\n",
            "Epoch 403/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4153 - accuracy: 0.8793 - val_loss: 0.9311 - val_accuracy: 0.6235\n",
            "Epoch 404/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4035 - accuracy: 0.8856 - val_loss: 0.9334 - val_accuracy: 0.6229\n",
            "Epoch 405/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4063 - accuracy: 0.8879 - val_loss: 0.9328 - val_accuracy: 0.6241\n",
            "Epoch 406/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4091 - accuracy: 0.8748 - val_loss: 0.9288 - val_accuracy: 0.6212\n",
            "Epoch 407/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4116 - accuracy: 0.8848 - val_loss: 0.9342 - val_accuracy: 0.6200\n",
            "Epoch 408/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4061 - accuracy: 0.8837 - val_loss: 0.9281 - val_accuracy: 0.6235\n",
            "Epoch 409/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3997 - accuracy: 0.8865 - val_loss: 0.9306 - val_accuracy: 0.6217\n",
            "Epoch 410/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.3986 - accuracy: 0.8848 - val_loss: 0.9265 - val_accuracy: 0.6223\n",
            "Epoch 411/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4039 - accuracy: 0.8844 - val_loss: 0.9318 - val_accuracy: 0.6176\n",
            "Epoch 412/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4110 - accuracy: 0.8751 - val_loss: 0.9307 - val_accuracy: 0.6229\n",
            "Epoch 413/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4163 - accuracy: 0.8779 - val_loss: 0.9323 - val_accuracy: 0.6247\n",
            "Epoch 414/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4161 - accuracy: 0.8788 - val_loss: 0.9317 - val_accuracy: 0.6253\n",
            "Epoch 415/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4072 - accuracy: 0.8817 - val_loss: 0.9288 - val_accuracy: 0.6265\n",
            "Epoch 416/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4092 - accuracy: 0.8805 - val_loss: 0.9339 - val_accuracy: 0.6206\n",
            "Epoch 417/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4165 - accuracy: 0.8757 - val_loss: 0.9261 - val_accuracy: 0.6212\n",
            "Epoch 418/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4222 - accuracy: 0.8706 - val_loss: 0.9255 - val_accuracy: 0.6223\n",
            "Epoch 419/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4054 - accuracy: 0.8804 - val_loss: 0.9262 - val_accuracy: 0.6229\n",
            "Epoch 420/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4285 - accuracy: 0.8692 - val_loss: 0.9264 - val_accuracy: 0.6300\n",
            "Epoch 421/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4176 - accuracy: 0.8819 - val_loss: 0.9244 - val_accuracy: 0.6170\n",
            "Epoch 422/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4155 - accuracy: 0.8794 - val_loss: 0.9254 - val_accuracy: 0.6259\n",
            "Epoch 423/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4134 - accuracy: 0.8808 - val_loss: 0.9248 - val_accuracy: 0.6271\n",
            "Epoch 424/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4157 - accuracy: 0.8794 - val_loss: 0.9242 - val_accuracy: 0.6259\n",
            "Epoch 425/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4178 - accuracy: 0.8754 - val_loss: 0.9286 - val_accuracy: 0.6176\n",
            "Epoch 426/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4148 - accuracy: 0.8753 - val_loss: 0.9266 - val_accuracy: 0.6158\n",
            "Epoch 427/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4192 - accuracy: 0.8744 - val_loss: 0.9319 - val_accuracy: 0.6158\n",
            "Epoch 428/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4212 - accuracy: 0.8783 - val_loss: 0.9239 - val_accuracy: 0.6271\n",
            "Epoch 429/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4203 - accuracy: 0.8745 - val_loss: 0.9253 - val_accuracy: 0.6229\n",
            "Epoch 430/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4192 - accuracy: 0.8742 - val_loss: 0.9349 - val_accuracy: 0.6212\n",
            "Epoch 431/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4187 - accuracy: 0.8745 - val_loss: 0.9228 - val_accuracy: 0.6259\n",
            "Epoch 432/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4136 - accuracy: 0.8802 - val_loss: 0.9332 - val_accuracy: 0.6176\n",
            "Epoch 433/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4193 - accuracy: 0.8780 - val_loss: 0.9275 - val_accuracy: 0.6217\n",
            "Epoch 434/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4271 - accuracy: 0.8696 - val_loss: 0.9219 - val_accuracy: 0.6229\n",
            "Epoch 435/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4201 - accuracy: 0.8789 - val_loss: 0.9296 - val_accuracy: 0.6217\n",
            "Epoch 436/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4316 - accuracy: 0.8696 - val_loss: 0.9307 - val_accuracy: 0.6164\n",
            "Epoch 437/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4176 - accuracy: 0.8792 - val_loss: 0.9266 - val_accuracy: 0.6241\n",
            "Epoch 438/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4184 - accuracy: 0.8758 - val_loss: 0.9286 - val_accuracy: 0.6265\n",
            "Epoch 439/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4095 - accuracy: 0.8822 - val_loss: 0.9225 - val_accuracy: 0.6194\n",
            "Epoch 440/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4323 - accuracy: 0.8639 - val_loss: 0.9331 - val_accuracy: 0.6170\n",
            "Epoch 441/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4172 - accuracy: 0.8762 - val_loss: 0.9206 - val_accuracy: 0.6217\n",
            "Epoch 442/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4214 - accuracy: 0.8759 - val_loss: 0.9272 - val_accuracy: 0.6229\n",
            "Epoch 443/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4161 - accuracy: 0.8778 - val_loss: 0.9197 - val_accuracy: 0.6247\n",
            "Epoch 444/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4165 - accuracy: 0.8778 - val_loss: 0.9346 - val_accuracy: 0.6235\n",
            "Epoch 445/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4181 - accuracy: 0.8764 - val_loss: 0.9171 - val_accuracy: 0.6194\n",
            "Epoch 446/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4268 - accuracy: 0.8746 - val_loss: 0.9306 - val_accuracy: 0.6259\n",
            "Epoch 447/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4156 - accuracy: 0.8772 - val_loss: 0.9239 - val_accuracy: 0.6164\n",
            "Epoch 448/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4238 - accuracy: 0.8758 - val_loss: 0.9286 - val_accuracy: 0.6229\n",
            "Epoch 449/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4216 - accuracy: 0.8756 - val_loss: 0.9251 - val_accuracy: 0.6259\n",
            "Epoch 450/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4285 - accuracy: 0.8648 - val_loss: 0.9266 - val_accuracy: 0.6259\n",
            "Epoch 451/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4250 - accuracy: 0.8693 - val_loss: 0.9266 - val_accuracy: 0.6259\n",
            "Epoch 452/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4165 - accuracy: 0.8790 - val_loss: 0.9228 - val_accuracy: 0.6235\n",
            "Epoch 453/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4196 - accuracy: 0.8803 - val_loss: 0.9213 - val_accuracy: 0.6259\n",
            "Epoch 454/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4167 - accuracy: 0.8728 - val_loss: 0.9166 - val_accuracy: 0.6283\n",
            "Epoch 455/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4260 - accuracy: 0.8746 - val_loss: 0.9218 - val_accuracy: 0.6176\n",
            "Epoch 456/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4180 - accuracy: 0.8765 - val_loss: 0.9190 - val_accuracy: 0.6241\n",
            "Epoch 457/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4219 - accuracy: 0.8745 - val_loss: 0.9237 - val_accuracy: 0.6206\n",
            "Epoch 458/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4260 - accuracy: 0.8738 - val_loss: 0.9274 - val_accuracy: 0.6217\n",
            "Epoch 459/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4267 - accuracy: 0.8672 - val_loss: 0.9270 - val_accuracy: 0.6200\n",
            "Epoch 460/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4299 - accuracy: 0.8695 - val_loss: 0.9331 - val_accuracy: 0.6229\n",
            "Epoch 461/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4287 - accuracy: 0.8716 - val_loss: 0.9169 - val_accuracy: 0.6247\n",
            "Epoch 462/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4126 - accuracy: 0.8843 - val_loss: 0.9276 - val_accuracy: 0.6223\n",
            "Epoch 463/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4247 - accuracy: 0.8754 - val_loss: 0.9213 - val_accuracy: 0.6277\n",
            "Epoch 464/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4405 - accuracy: 0.8601 - val_loss: 0.9248 - val_accuracy: 0.6229\n",
            "Epoch 465/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4191 - accuracy: 0.8784 - val_loss: 0.9228 - val_accuracy: 0.6241\n",
            "Epoch 466/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4090 - accuracy: 0.8800 - val_loss: 0.9188 - val_accuracy: 0.6300\n",
            "Epoch 467/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4371 - accuracy: 0.8684 - val_loss: 0.9187 - val_accuracy: 0.6247\n",
            "Epoch 468/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4410 - accuracy: 0.8587 - val_loss: 0.9287 - val_accuracy: 0.6223\n",
            "Epoch 469/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4350 - accuracy: 0.8717 - val_loss: 0.9198 - val_accuracy: 0.6277\n",
            "\n",
            "Epoch 00469: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 470/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4280 - accuracy: 0.8662 - val_loss: 0.9160 - val_accuracy: 0.6294\n",
            "Epoch 471/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4197 - accuracy: 0.8770 - val_loss: 0.9233 - val_accuracy: 0.6235\n",
            "Epoch 472/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4178 - accuracy: 0.8767 - val_loss: 0.9169 - val_accuracy: 0.6212\n",
            "Epoch 473/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4347 - accuracy: 0.8720 - val_loss: 0.9180 - val_accuracy: 0.6265\n",
            "Epoch 474/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4326 - accuracy: 0.8704 - val_loss: 0.9144 - val_accuracy: 0.6259\n",
            "Epoch 475/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4408 - accuracy: 0.8618 - val_loss: 0.9219 - val_accuracy: 0.6277\n",
            "Epoch 476/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4529 - accuracy: 0.8577 - val_loss: 0.9155 - val_accuracy: 0.6300\n",
            "Epoch 477/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4363 - accuracy: 0.8668 - val_loss: 0.9168 - val_accuracy: 0.6265\n",
            "Epoch 478/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4178 - accuracy: 0.8825 - val_loss: 0.9192 - val_accuracy: 0.6223\n",
            "Epoch 479/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.4416 - accuracy: 0.8725 - val_loss: 0.9162 - val_accuracy: 0.6288\n",
            "Epoch 480/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4384 - accuracy: 0.8741 - val_loss: 0.9162 - val_accuracy: 0.6265\n",
            "Epoch 481/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4473 - accuracy: 0.8682 - val_loss: 0.9198 - val_accuracy: 0.6241\n",
            "Epoch 482/1000\n",
            "27/27 [==============================] - 1s 43ms/step - loss: 0.4406 - accuracy: 0.8789 - val_loss: 0.9153 - val_accuracy: 0.6277\n",
            "Epoch 483/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4438 - accuracy: 0.8746 - val_loss: 0.9162 - val_accuracy: 0.6288\n",
            "Epoch 484/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4447 - accuracy: 0.8717 - val_loss: 0.9150 - val_accuracy: 0.6235\n",
            "Epoch 485/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4540 - accuracy: 0.8667 - val_loss: 0.9142 - val_accuracy: 0.6259\n",
            "Epoch 486/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4441 - accuracy: 0.8726 - val_loss: 0.9160 - val_accuracy: 0.6288\n",
            "Epoch 487/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4474 - accuracy: 0.8703 - val_loss: 0.9139 - val_accuracy: 0.6241\n",
            "Epoch 488/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4486 - accuracy: 0.8720 - val_loss: 0.9128 - val_accuracy: 0.6283\n",
            "Epoch 489/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4573 - accuracy: 0.8667 - val_loss: 0.9092 - val_accuracy: 0.6312\n",
            "Epoch 490/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4615 - accuracy: 0.8632 - val_loss: 0.9129 - val_accuracy: 0.6288\n",
            "Epoch 491/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4618 - accuracy: 0.8643 - val_loss: 0.9150 - val_accuracy: 0.6271\n",
            "Epoch 492/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4555 - accuracy: 0.8650 - val_loss: 0.9109 - val_accuracy: 0.6306\n",
            "Epoch 493/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4722 - accuracy: 0.8609 - val_loss: 0.9124 - val_accuracy: 0.6288\n",
            "Epoch 494/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4663 - accuracy: 0.8636 - val_loss: 0.9129 - val_accuracy: 0.6306\n",
            "Epoch 495/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4742 - accuracy: 0.8559 - val_loss: 0.9111 - val_accuracy: 0.6359\n",
            "Epoch 496/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4728 - accuracy: 0.8628 - val_loss: 0.9139 - val_accuracy: 0.6312\n",
            "Epoch 497/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4690 - accuracy: 0.8686 - val_loss: 0.9116 - val_accuracy: 0.6259\n",
            "Epoch 498/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4565 - accuracy: 0.8780 - val_loss: 0.9161 - val_accuracy: 0.6294\n",
            "Epoch 499/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4755 - accuracy: 0.8646 - val_loss: 0.9154 - val_accuracy: 0.6288\n",
            "Epoch 500/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4767 - accuracy: 0.8623 - val_loss: 0.9192 - val_accuracy: 0.6229\n",
            "Epoch 501/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4765 - accuracy: 0.8613 - val_loss: 0.9090 - val_accuracy: 0.6318\n",
            "Epoch 502/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4767 - accuracy: 0.8565 - val_loss: 0.9131 - val_accuracy: 0.6318\n",
            "Epoch 503/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4827 - accuracy: 0.8621 - val_loss: 0.9104 - val_accuracy: 0.6318\n",
            "Epoch 504/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4933 - accuracy: 0.8561 - val_loss: 0.9093 - val_accuracy: 0.6312\n",
            "Epoch 505/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4810 - accuracy: 0.8630 - val_loss: 0.9093 - val_accuracy: 0.6348\n",
            "Epoch 506/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4993 - accuracy: 0.8494 - val_loss: 0.9130 - val_accuracy: 0.6306\n",
            "Epoch 507/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4865 - accuracy: 0.8674 - val_loss: 0.9130 - val_accuracy: 0.6288\n",
            "Epoch 508/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4841 - accuracy: 0.8617 - val_loss: 0.9110 - val_accuracy: 0.6300\n",
            "Epoch 509/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4870 - accuracy: 0.8571 - val_loss: 0.9127 - val_accuracy: 0.6318\n",
            "Epoch 510/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4937 - accuracy: 0.8504 - val_loss: 0.9093 - val_accuracy: 0.6371\n",
            "Epoch 511/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.4840 - accuracy: 0.8672 - val_loss: 0.9130 - val_accuracy: 0.6312\n",
            "Epoch 512/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4983 - accuracy: 0.8581 - val_loss: 0.9105 - val_accuracy: 0.6383\n",
            "Epoch 513/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4969 - accuracy: 0.8611 - val_loss: 0.9105 - val_accuracy: 0.6336\n",
            "Epoch 514/1000\n",
            "27/27 [==============================] - 1s 42ms/step - loss: 0.4977 - accuracy: 0.8568 - val_loss: 0.9135 - val_accuracy: 0.6330\n",
            "Epoch 515/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5021 - accuracy: 0.8572 - val_loss: 0.9110 - val_accuracy: 0.6312\n",
            "Epoch 516/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5082 - accuracy: 0.8550 - val_loss: 0.9106 - val_accuracy: 0.6336\n",
            "\n",
            "Epoch 00516: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 517/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5068 - accuracy: 0.8536 - val_loss: 0.9084 - val_accuracy: 0.6342\n",
            "Epoch 518/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5016 - accuracy: 0.8606 - val_loss: 0.9076 - val_accuracy: 0.6353\n",
            "Epoch 519/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.4998 - accuracy: 0.8558 - val_loss: 0.9089 - val_accuracy: 0.6330\n",
            "Epoch 520/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5005 - accuracy: 0.8574 - val_loss: 0.9101 - val_accuracy: 0.6342\n",
            "Epoch 521/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5205 - accuracy: 0.8512 - val_loss: 0.9122 - val_accuracy: 0.6324\n",
            "Epoch 522/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5047 - accuracy: 0.8631 - val_loss: 0.9144 - val_accuracy: 0.6306\n",
            "Epoch 523/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5152 - accuracy: 0.8570 - val_loss: 0.9157 - val_accuracy: 0.6336\n",
            "Epoch 524/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5250 - accuracy: 0.8510 - val_loss: 0.9145 - val_accuracy: 0.6359\n",
            "Epoch 525/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5186 - accuracy: 0.8569 - val_loss: 0.9160 - val_accuracy: 0.6348\n",
            "Epoch 526/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5194 - accuracy: 0.8577 - val_loss: 0.9147 - val_accuracy: 0.6330\n",
            "Epoch 527/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5400 - accuracy: 0.8481 - val_loss: 0.9173 - val_accuracy: 0.6359\n",
            "Epoch 528/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5331 - accuracy: 0.8544 - val_loss: 0.9151 - val_accuracy: 0.6371\n",
            "Epoch 529/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5267 - accuracy: 0.8525 - val_loss: 0.9155 - val_accuracy: 0.6342\n",
            "Epoch 530/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5318 - accuracy: 0.8597 - val_loss: 0.9185 - val_accuracy: 0.6342\n",
            "Epoch 531/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5355 - accuracy: 0.8508 - val_loss: 0.9189 - val_accuracy: 0.6359\n",
            "Epoch 532/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5362 - accuracy: 0.8557 - val_loss: 0.9158 - val_accuracy: 0.6365\n",
            "Epoch 533/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5490 - accuracy: 0.8518 - val_loss: 0.9196 - val_accuracy: 0.6353\n",
            "\n",
            "Epoch 00533: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 534/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5394 - accuracy: 0.8491 - val_loss: 0.9211 - val_accuracy: 0.6365\n",
            "Epoch 535/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5562 - accuracy: 0.8532 - val_loss: 0.9191 - val_accuracy: 0.6389\n",
            "Epoch 536/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5465 - accuracy: 0.8416 - val_loss: 0.9205 - val_accuracy: 0.6359\n",
            "Epoch 537/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5477 - accuracy: 0.8562 - val_loss: 0.9218 - val_accuracy: 0.6365\n",
            "Epoch 538/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5548 - accuracy: 0.8488 - val_loss: 0.9230 - val_accuracy: 0.6383\n",
            "Epoch 539/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5520 - accuracy: 0.8515 - val_loss: 0.9233 - val_accuracy: 0.6371\n",
            "Epoch 540/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5615 - accuracy: 0.8525 - val_loss: 0.9248 - val_accuracy: 0.6365\n",
            "Epoch 541/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5715 - accuracy: 0.8493 - val_loss: 0.9265 - val_accuracy: 0.6371\n",
            "Epoch 542/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5871 - accuracy: 0.8446 - val_loss: 0.9268 - val_accuracy: 0.6389\n",
            "Epoch 543/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5615 - accuracy: 0.8621 - val_loss: 0.9278 - val_accuracy: 0.6389\n",
            "Epoch 544/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5731 - accuracy: 0.8465 - val_loss: 0.9286 - val_accuracy: 0.6377\n",
            "Epoch 545/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5882 - accuracy: 0.8537 - val_loss: 0.9306 - val_accuracy: 0.6383\n",
            "Epoch 546/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5844 - accuracy: 0.8482 - val_loss: 0.9319 - val_accuracy: 0.6353\n",
            "Epoch 547/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5880 - accuracy: 0.8508 - val_loss: 0.9323 - val_accuracy: 0.6359\n",
            "Epoch 548/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5880 - accuracy: 0.8433 - val_loss: 0.9330 - val_accuracy: 0.6371\n",
            "\n",
            "Epoch 00548: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "Epoch 549/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.5902 - accuracy: 0.8431 - val_loss: 0.9342 - val_accuracy: 0.6353\n",
            "Epoch 550/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6018 - accuracy: 0.8347 - val_loss: 0.9359 - val_accuracy: 0.6371\n",
            "Epoch 551/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.5980 - accuracy: 0.8450 - val_loss: 0.9375 - val_accuracy: 0.6383\n",
            "Epoch 552/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.6053 - accuracy: 0.8462 - val_loss: 0.9397 - val_accuracy: 0.6371\n",
            "Epoch 553/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6111 - accuracy: 0.8463 - val_loss: 0.9415 - val_accuracy: 0.6371\n",
            "Epoch 554/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6147 - accuracy: 0.8419 - val_loss: 0.9428 - val_accuracy: 0.6371\n",
            "Epoch 555/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6229 - accuracy: 0.8460 - val_loss: 0.9446 - val_accuracy: 0.6383\n",
            "Epoch 556/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6224 - accuracy: 0.8444 - val_loss: 0.9460 - val_accuracy: 0.6383\n",
            "Epoch 557/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6263 - accuracy: 0.8436 - val_loss: 0.9474 - val_accuracy: 0.6395\n",
            "Epoch 558/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6269 - accuracy: 0.8531 - val_loss: 0.9495 - val_accuracy: 0.6418\n",
            "Epoch 559/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6314 - accuracy: 0.8538 - val_loss: 0.9514 - val_accuracy: 0.6383\n",
            "Epoch 560/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6354 - accuracy: 0.8551 - val_loss: 0.9530 - val_accuracy: 0.6383\n",
            "Epoch 561/1000\n",
            "27/27 [==============================] - 1s 39ms/step - loss: 0.6309 - accuracy: 0.8516 - val_loss: 0.9542 - val_accuracy: 0.6389\n",
            "Epoch 562/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6475 - accuracy: 0.8415 - val_loss: 0.9562 - val_accuracy: 0.6389\n",
            "Epoch 563/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6606 - accuracy: 0.8355 - val_loss: 0.9585 - val_accuracy: 0.6365\n",
            "\n",
            "Epoch 00563: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "Epoch 564/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6595 - accuracy: 0.8411 - val_loss: 0.9604 - val_accuracy: 0.6371\n",
            "Epoch 565/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6548 - accuracy: 0.8365 - val_loss: 0.9625 - val_accuracy: 0.6365\n",
            "Epoch 566/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6605 - accuracy: 0.8483 - val_loss: 0.9645 - val_accuracy: 0.6383\n",
            "Epoch 567/1000\n",
            "27/27 [==============================] - 1s 40ms/step - loss: 0.6676 - accuracy: 0.8453 - val_loss: 0.9663 - val_accuracy: 0.6383\n",
            "Epoch 568/1000\n",
            "27/27 [==============================] - 1s 41ms/step - loss: 0.6754 - accuracy: 0.8413 - val_loss: 0.9685 - val_accuracy: 0.6383\n",
            "Epoch 00568: early stopping\n",
            "56/56 [==============================] - 1s 13ms/step - loss: 0.9714 - accuracy: 0.5976\n",
            "Test accuracy: 59.76%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}